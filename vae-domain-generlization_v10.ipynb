{"cells":[{"cell_type":"code","execution_count":31,"metadata":{"_cell_guid":"63dff951-1f50-44fc-9aa0-551e349fa121","_uuid":"a488026f-5d31-43f0-8fb8-935050b9c511","collapsed":false,"execution":{"iopub.execute_input":"2024-10-09T11:00:38.673535Z","iopub.status.busy":"2024-10-09T11:00:38.673152Z","iopub.status.idle":"2024-10-09T11:00:38.680353Z","shell.execute_reply":"2024-10-09T11:00:38.679242Z","shell.execute_reply.started":"2024-10-09T11:00:38.673497Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms, models\n","from tqdm import tqdm\n","from PIL import Image\n","import os\n","import torch.nn.functional as F\n","from torch.nn.modules.loss import _WeightedLoss\n","from sklearn.model_selection import train_test_split\n","from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n","from torch.optim.swa_utils import AveragedModel, SWALR\n","from torch.autograd import Function"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2024-10-09T11:00:38.684570Z","iopub.status.busy":"2024-10-09T11:00:38.684177Z","iopub.status.idle":"2024-10-09T11:00:38.696979Z","shell.execute_reply":"2024-10-09T11:00:38.696221Z","shell.execute_reply.started":"2024-10-09T11:00:38.684525Z"},"trusted":true},"outputs":[],"source":["import random\n","import numpy as np\n","\n","def set_random_seeds(seed_value=42):\n","    torch.manual_seed(seed_value)\n","    torch.cuda.manual_seed(seed_value)\n","    torch.cuda.manual_seed_all(seed_value)  # if you are using multi-GPU.\n","    np.random.seed(seed_value)  # Numpy module.\n","    random.seed(seed_value)  # Python random module.\n","    torch.backends.cudnn.benchmark = False\n","    torch.backends.cudnn.deterministic = True\n","\n","set_random_seeds()"]},{"cell_type":"code","execution_count":33,"metadata":{"_cell_guid":"7e723a2a-1ccf-4e37-a6f9-d46f8694102b","_uuid":"7426537d-3ff8-4660-b5b0-2af7b0125e93","collapsed":false,"execution":{"iopub.execute_input":"2024-10-09T11:00:38.698631Z","iopub.status.busy":"2024-10-09T11:00:38.698316Z","iopub.status.idle":"2024-10-09T11:00:38.712669Z","shell.execute_reply":"2024-10-09T11:00:38.711809Z","shell.execute_reply.started":"2024-10-09T11:00:38.698600Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["class PACSDataset(Dataset):\n","    def __init__(self, root_dir, domains, transform=None):\n","        self.root_dir = root_dir\n","        self.domains = domains\n","        self.transform = transform\n","        self.images = []\n","        self.labels = []\n","        self._load_images_labels()\n","\n","    def _load_images_labels(self):\n","        for domain in self.domains:\n","            domain_dir = os.path.join(self.root_dir, domain)\n","            classes = sorted(\n","                [\n","                    d\n","                    for d in os.listdir(domain_dir)\n","                    if os.path.isdir(os.path.join(domain_dir, d))\n","                ]\n","            )\n","\n","            for label, class_name in enumerate(classes):\n","                class_dir = os.path.join(domain_dir, class_name)\n","                for image_name in os.listdir(class_dir):\n","                    if image_name.endswith((\".png\", \".jpg\", \".jpeg\")):\n","                        self.images.append(os.path.join(class_dir, image_name))\n","                        self.labels.append(label)\n","\n","    def __len__(self):\n","        return len(self.images)\n","\n","    def __getitem__(self, idx):\n","        image_path = self.images[idx]\n","        image = Image.open(image_path).convert(\"RGB\")\n","        label = self.labels[idx]\n","\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        # Kiểm tra xem hình ảnh có giá trị NaN hay không\n","        if torch.isnan(image).any():\n","            raise ValueError(f\"Image at index {idx} contains NaN values.\")\n","\n","        return image, label\n","\n","def get_transform():\n","    return transforms.Compose([\n","        transforms.Resize((224, 224)),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.RandomRotation(10),\n","        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","        transforms.RandomErasing(p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3), value=0),\n","    ])"]},{"cell_type":"code","execution_count":34,"metadata":{"_cell_guid":"548b7f7d-1ff5-4a1f-baf4-31e56ac36106","_uuid":"9005ce9d-75fd-4ce6-ac55-316bbb464e42","collapsed":false,"execution":{"iopub.execute_input":"2024-10-09T11:00:38.716157Z","iopub.status.busy":"2024-10-09T11:00:38.715355Z","iopub.status.idle":"2024-10-09T11:00:38.726141Z","shell.execute_reply":"2024-10-09T11:00:38.725249Z","shell.execute_reply.started":"2024-10-09T11:00:38.716108Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["def get_dataloader(root_dir, train_domains, test_domain, batch_size=16):\n","    train_dataset = PACSDataset(root_dir, train_domains, transform=get_transform())\n","    val_dataset = PACSDataset(root_dir, train_domains, transform=get_transform())\n","    test_dataset = PACSDataset(root_dir, [test_domain], transform=get_transform())\n","    \n","    # Chia train và validation\n","    train_size = int(0.9 * len(train_dataset))\n","    val_size = len(train_dataset) - train_size\n","    train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n","    \n","    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n","    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n","    \n","    return train_loader, val_loader, test_loader"]},{"cell_type":"code","execution_count":35,"metadata":{"_cell_guid":"6082ed00-9929-4bc1-afb9-e5560ee9b021","_uuid":"9044088f-c60e-4975-9124-713fe31e3127","collapsed":false,"execution":{"iopub.execute_input":"2024-10-09T11:00:38.727592Z","iopub.status.busy":"2024-10-09T11:00:38.727307Z","iopub.status.idle":"2024-10-09T11:00:38.743738Z","shell.execute_reply":"2024-10-09T11:00:38.743050Z","shell.execute_reply.started":"2024-10-09T11:00:38.727549Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["from torchvision.models import efficientnet_b7\n","\n","class Encoder(nn.Module):\n","    def __init__(self, latent_dim):\n","        super(Encoder, self).__init__()\n","\n","        # Khởi tạo mô hình EfficientNet-B1 mà không sử dụng pretrained weights\n","        # self.efficientnet = efficientnet_b7(weights=models.EfficientNet_B7_Weights.IMAGENET1K_V1)\n","        self.efficientnet = efficientnet_b7(weights=None)\n","\n","        # Lấy số features từ lớp cuối cùng của EfficientNet-B1\n","        in_features = self.efficientnet.classifier[1].in_features\n","\n","        # Attention mechanism\n","        self.attention = nn.Sequential(\n","            nn.Linear(in_features, in_features // 16),\n","            nn.ReLU(),\n","            nn.Linear(in_features // 16, in_features),\n","            nn.Sigmoid(),\n","        )\n","\n","        # Mean (mu) and log-variance (logvar) layers\n","        self.fc_mu = nn.Linear(in_features, latent_dim)\n","        self.fc_logvar = nn.Linear(in_features, latent_dim)\n","\n","        self.dropout = nn.Dropout(0.5)  # Add dropout\n","\n","    def forward(self, x):\n","        # Pass input through EfficientNet feature extractor\n","        features = self.efficientnet.features(x)\n","        x = self.efficientnet.avgpool(features)\n","        x = torch.flatten(x, 1)\n","\n","        x = self.dropout(x)  # Apply dropout\n","\n","        # Apply attention\n","        attention_weights = self.attention(x)\n","        x = x * attention_weights\n","\n","        # Compute mu and logvar\n","        mu = self.fc_mu(x)\n","        logvar = self.fc_logvar(x)\n","        return mu, logvar"]},{"cell_type":"code","execution_count":36,"metadata":{"_cell_guid":"2a2a7eed-8a05-4a1b-8da2-f70d4eca373a","_uuid":"4a788999-5aa5-49b7-8322-d9cf74c8cb11","collapsed":false,"execution":{"iopub.execute_input":"2024-10-09T11:00:38.744956Z","iopub.status.busy":"2024-10-09T11:00:38.744679Z","iopub.status.idle":"2024-10-09T11:00:38.756016Z","shell.execute_reply":"2024-10-09T11:00:38.755081Z","shell.execute_reply.started":"2024-10-09T11:00:38.744925Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["class Classifier(nn.Module):\n","    def __init__(self, latent_dim, num_classes):\n","        super(Classifier, self).__init__()\n","        self.fc = nn.Linear(latent_dim, num_classes)\n","        self.dropout = nn.Dropout(0.5)\n","\n","    def forward(self, z):\n","        z = self.dropout(z)\n","        return self.fc(z)"]},{"cell_type":"code","execution_count":37,"metadata":{"_cell_guid":"16f849a2-ff32-4d43-829d-3c1d2aa228b2","_uuid":"9dd26907-bdc8-4ee1-be90-1727b7be2e5e","collapsed":false,"execution":{"iopub.execute_input":"2024-10-09T11:00:38.757747Z","iopub.status.busy":"2024-10-09T11:00:38.757348Z","iopub.status.idle":"2024-10-09T11:00:38.771181Z","shell.execute_reply":"2024-10-09T11:00:38.770390Z","shell.execute_reply.started":"2024-10-09T11:00:38.757705Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["class Decoder(nn.Module):\n","    def __init__(self, latent_dim, num_domains):\n","        super(Decoder, self).__init__()\n","        self.domain_embedding = nn.Embedding(num_domains, latent_dim)\n","        \n","        self.init_conv = nn.Conv2d(latent_dim, 512, 3, padding=1)\n","        \n","        self.up1 = UNetUpBlock(512, 256)\n","        self.up2 = UNetUpBlock(256, 128)\n","        self.up3 = UNetUpBlock(128, 64)\n","        self.up4 = UNetUpBlock(64, 32)\n","        self.up5 = UNetUpBlock(32, 16)\n","        \n","        self.final_conv = nn.Conv2d(16, 3, 3, padding=1)\n","        self.attention = nn.Sequential(nn.Conv2d(3, 1, kernel_size=1), nn.Sigmoid())\n","\n","    def forward(self, z, domain_label):\n","        domain_embed = self.domain_embedding(domain_label)\n","        z = z + domain_embed\n","        \n","        x = z.view(-1, z.size(1), 1, 1)\n","        x = F.interpolate(x, size=(7, 7), mode='bilinear', align_corners=False)\n","        x = self.init_conv(x)\n","        \n","        x = self.up1(x)\n","        x = self.up2(x)\n","        x = self.up3(x)\n","        x = self.up4(x)\n","        x = self.up5(x)\n","        \n","        x = self.final_conv(x)\n","        \n","        attention_map = self.attention(x)\n","        x = x * attention_map\n","        \n","        return x\n","\n","class UNetUpBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(UNetUpBlock, self).__init__()\n","        self.conv = nn.Sequential(\n","            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(out_channels, out_channels, 3, padding=1),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True)\n","        )\n","        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n","\n","    def forward(self, x):\n","        x = self.upsample(x)\n","        return self.conv(x)"]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2024-10-09T11:00:38.772408Z","iopub.status.busy":"2024-10-09T11:00:38.772137Z","iopub.status.idle":"2024-10-09T11:00:38.786403Z","shell.execute_reply":"2024-10-09T11:00:38.785515Z","shell.execute_reply.started":"2024-10-09T11:00:38.772378Z"},"trusted":true},"outputs":[],"source":["class DomainClassifier(nn.Module):\n","    def __init__(self, latent_dim, num_domains=3):\n","        super(DomainClassifier, self).__init__()\n","        self.fc1 = nn.Linear(latent_dim, 1024)\n","        self.fc2 = nn.Linear(1024, 1024)\n","        self.fc3 = nn.Linear(1024, num_domains)\n","        self.dropout = nn.Dropout(0.5)\n","\n","    def forward(self, x):\n","        x = F.relu(self.fc1(x))\n","        x = self.dropout(x)\n","        x = F.relu(self.fc2(x))\n","        x = self.dropout(x)\n","        x = self.fc3(x)\n","        return x\n","\n","\n","class GradientReversalLayer(Function):\n","    @staticmethod\n","    def forward(ctx, x, alpha):\n","        ctx.alpha = alpha\n","        return x.view_as(x)\n","\n","    @staticmethod\n","    def backward(ctx, grad_output):\n","        return grad_output.neg() * ctx.alpha, None\n","\n","def grad_reverse(x, alpha):\n","    return GradientReversalLayer.apply(x, alpha)"]},{"cell_type":"code","execution_count":39,"metadata":{"_cell_guid":"730d8196-518b-434d-b0df-68024fcbf6cd","_uuid":"c7ec10b7-90b2-4f72-83a3-7b5fff0f3bb2","collapsed":false,"execution":{"iopub.execute_input":"2024-10-09T11:00:38.788173Z","iopub.status.busy":"2024-10-09T11:00:38.787513Z","iopub.status.idle":"2024-10-09T11:00:38.804202Z","shell.execute_reply":"2024-10-09T11:00:38.803359Z","shell.execute_reply.started":"2024-10-09T11:00:38.788141Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["class LabelSmoothingLoss(_WeightedLoss):\n","    def __init__(self, weight=None, reduction=\"mean\", smoothing=0.0):\n","        super().__init__(weight=weight, reduction=reduction)\n","        self.smoothing = smoothing\n","        self.weight = weight\n","        self.reduction = reduction\n","\n","    def k_one_hot(self, targets: torch.Tensor, n_classes: int, smoothing=0.0):\n","        with torch.no_grad():\n","            targets = (\n","                torch.empty(size=(targets.size(0), n_classes), device=targets.device)\n","                .fill_(smoothing / (n_classes - 1))\n","                .scatter_(1, targets.data.unsqueeze(1), 1.0 - smoothing)\n","            )\n","        return targets\n","\n","    def reduce_loss(self, loss):\n","        return (\n","            loss.mean()\n","            if self.reduction == \"mean\"\n","            else loss.sum() if self.reduction == \"sum\" else loss\n","        )\n","\n","    def forward(self, inputs, targets):\n","        assert 0 <= self.smoothing < 1\n","\n","        targets = self.k_one_hot(targets, inputs.size(-1), self.smoothing)\n","        log_preds = F.log_softmax(inputs, -1)\n","\n","        if self.weight is not None:\n","            log_preds = log_preds * self.weight.unsqueeze(0)\n","\n","        return self.reduce_loss(-(targets * log_preds).sum(dim=-1))\n","\n","class DynamicWeightBalancer:\n","    def __init__(self, init_alpha=1.0, init_beta=1.0, init_gamma=1.0, init_delta=1.0, patience=5, scaling_factor=0.7):\n","        self.alpha = init_alpha  # Reconstruction loss weight\n","        self.beta = init_beta    # Classification loss weight\n","        self.gamma = init_gamma  # KL divergence weight\n","        self.delta = init_delta  # Domain loss weight\n","        \n","        self.patience = patience\n","        self.scaling_factor = scaling_factor\n","        self.best_loss = float('inf')\n","        self.counter = 0\n","\n","    def update(self, current_loss, recon_loss, clf_loss, kl_loss, domain_loss):\n","        if current_loss < self.best_loss:\n","            self.best_loss = current_loss\n","            self.counter = 0\n","        else:\n","            self.counter += 1\n","\n","        if self.counter >= self.patience:\n","            self.counter = 0\n","            # Increase classification weight and decrease others\n","            self.beta /= self.scaling_factor\n","            self.alpha *= self.scaling_factor\n","            self.gamma *= self.scaling_factor\n","            self.delta *= self.scaling_factor\n","\n","        # Ensure classification loss weight is always significantly larger\n","        total_weight = self.alpha + self.beta + self.gamma + self.delta\n","        self.alpha = max(0.1, min(0.3, self.alpha / total_weight))\n","        self.beta = max(0.6, min(0.8, self.beta / total_weight))\n","        self.gamma = max(0.05, min(0.15, self.gamma / total_weight))\n","        self.delta = 1 - self.alpha - self.beta - self.gamma\n","\n","        return self.alpha, self.beta, self.gamma, self.delta"]},{"cell_type":"code","execution_count":40,"metadata":{"_cell_guid":"0f928d4b-fb33-4563-be80-781fc312ad46","_uuid":"579bedc2-0c1b-4b34-9381-51adf44ab5a6","collapsed":false,"execution":{"iopub.execute_input":"2024-10-09T11:00:38.806909Z","iopub.status.busy":"2024-10-09T11:00:38.806604Z","iopub.status.idle":"2024-10-09T11:00:38.818520Z","shell.execute_reply":"2024-10-09T11:00:38.817713Z","shell.execute_reply.started":"2024-10-09T11:00:38.806854Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["def reparameterize(mu, logvar, dropout_rate=0.5):\n","    std = torch.exp(0.5 * logvar)\n","    eps = torch.randn_like(std)\n","    z = mu + eps * std\n","    z = F.dropout(z, p=dropout_rate, training=True)  # Apply dropout\n","    return z\n","\n","def compute_loss(\n","    reconstructed_imgs_list,\n","    original_imgs,\n","    mu,\n","    logvar,\n","    predicted_labels,\n","    true_labels,\n","    domain_predictions,\n","    domain_labels,\n","    clf_loss_fn,\n","    domain_loss_fn,\n","    epoch,\n","    total_epochs,\n","    balancer,\n","):\n","    recon_loss = sum(\n","        F.mse_loss(recon, original_imgs, reduction=\"mean\")\n","        for recon in reconstructed_imgs_list\n","    ) / len(reconstructed_imgs_list)\n","\n","    kld_loss = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n","    clf_loss = clf_loss_fn(predicted_labels, true_labels)\n","    domain_loss = domain_loss_fn(domain_predictions, domain_labels)\n","\n","    #     alpha, beta, gamma, delta = balancer.update(\n","    #         recon_loss + clf_loss + kld_loss + domain_loss,\n","    #         recon_loss,\n","    #         clf_loss,\n","    #         kld_loss,\n","    #         domain_loss,\n","    #     )\n","    alpha = 0.1\n","    beta = 1\n","    gamma = 0.1\n","    delta = 0.2\n","    \n","    total_loss = (\n","        alpha * recon_loss + beta * clf_loss + gamma * kld_loss - delta * domain_loss\n","    )\n","    return (\n","        total_loss,\n","        recon_loss.item(),\n","        clf_loss.item(),\n","        kld_loss.item(),\n","        domain_loss.item(),\n","        alpha,\n","        beta,\n","        gamma,\n","        delta,\n","    )\n"]},{"cell_type":"code","execution_count":41,"metadata":{"_cell_guid":"f837665f-6b5c-4981-b75f-347fd51ea73e","_uuid":"1e67776f-61d3-4b15-92a5-eee4e01ea50a","collapsed":false,"execution":{"iopub.execute_input":"2024-10-09T11:00:38.819939Z","iopub.status.busy":"2024-10-09T11:00:38.819633Z","iopub.status.idle":"2024-10-09T11:00:38.832359Z","shell.execute_reply":"2024-10-09T11:00:38.831572Z","shell.execute_reply.started":"2024-10-09T11:00:38.819904Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["def mixup_data(x, y, alpha=1.0, device=\"cuda\"):\n","    if alpha > 0:\n","        lam = np.random.beta(alpha, alpha)\n","    else:\n","        lam = 1\n","\n","    batch_size = x.size()[0]\n","    index = torch.randperm(batch_size).to(device)\n","\n","    mixed_x = lam * x + (1 - lam) * x[index, :]\n","    y_a, y_b = y, y[index]\n","    return mixed_x, y_a, y_b, lam\n","\n","\n","def mixup_criterion(criterion, pred, y_a, y_b, lam):\n","    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)"]},{"cell_type":"code","execution_count":42,"metadata":{"_cell_guid":"5b019da2-c4d0-4851-a92d-42ae15a61e99","_uuid":"c70dffc2-be00-4ebd-8ab7-75e1f36da254","collapsed":false,"execution":{"iopub.execute_input":"2024-10-09T11:00:38.834225Z","iopub.status.busy":"2024-10-09T11:00:38.833919Z","iopub.status.idle":"2024-10-09T11:00:38.864914Z","shell.execute_reply":"2024-10-09T11:00:38.864028Z","shell.execute_reply.started":"2024-10-09T11:00:38.834194Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["import copy\n","\n","\n","def train_model_progressive(\n","    encoder,\n","    decoders,\n","    classifier,\n","    domain_classifier,\n","    train_domains,\n","    test_domain,\n","    train_loader,\n","    val_loader,\n","    test_loader,\n","    optimizer,\n","    scheduler,\n","    num_epochs=100,\n","    device=\"cuda\",\n","    patience=10,\n","):\n","    print(\"Training model with progressive domain adaptation\")\n","    print(f\"Number of epochs: {num_epochs}\")\n","    print(f\"Patience: {patience}\")\n","    print(f\"Train domains: {train_domains}\")\n","    print(f\"Test domain: {test_domain}\")\n","    print(f\"Device: {device}\")\n","    print(f\"Number of training samples: {len(train_loader.dataset)}\")\n","    print(f\"Number of validation samples: {len(val_loader.dataset)}\")\n","    print(f\"Number of test samples: {len(test_loader.dataset)}\")\n","\n","    clf_loss_fn = LabelSmoothingLoss(smoothing=0.1)\n","    domain_to_idx = {\n","        domain: idx for idx, domain in enumerate(train_domains + [test_domain])\n","    }\n","    domain_loss_fn = nn.CrossEntropyLoss()\n","    best_loss = float(\"inf\")\n","    best_test_accuracy = 0.0\n","    patience_counter = 0\n","    balancer = DynamicWeightBalancer()\n","\n","    # Để lưu mô hình tốt nhất\n","    best_model = {\"encoder\": None, \"decoders\": None, \"classifier\": None, \"domain_classifier\": None}\n","\n","    for epoch in range(num_epochs):\n","        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n","        encoder.train()\n","        classifier.train()\n","        for domain in train_domains:\n","            decoders[domain].train()\n","\n","        running_loss = 0.0\n","        running_recon_loss = 0.0\n","        running_clf_loss = 0.0\n","        running_kl_loss = 0.0\n","        total_samples = 0\n","\n","        # Training loop on train dataset\n","        for inputs, labels in tqdm(train_loader, desc=\"Training\"):\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            domain_labels = torch.zeros(inputs.size(0), 1).to(\n","                device\n","            )  # 0 for source domain\n","            inputs, labels_a, labels_b, lam = mixup_data(\n","                inputs, labels, alpha=0.2, device=device\n","            )\n","\n","            mu, logvar = encoder(inputs)\n","            z = reparameterize(mu, logvar)\n","\n","            # Forward pass through domain classifier with gradient reversal\n","            p = float(epoch) / num_epochs\n","            alpha = 2.0 / (1.0 + np.exp(-10 * p)) - 1.0\n","            domain_predictions = domain_classifier(grad_reverse(z, alpha))\n","\n","            reconstructed_imgs_list = []\n","            for domain in train_domains:\n","                domain_label = torch.tensor(\n","                    [domain_to_idx[domain]] * inputs.size(0), device=device\n","                )\n","                reconstructed_imgs = decoders[domain](z, domain_label)\n","                reconstructed_imgs_list.append(reconstructed_imgs)\n","\n","            predicted_labels = classifier(z)\n","\n","            (\n","                loss,\n","                recon_loss,\n","                clf_loss,\n","                kl_loss,\n","                domain_loss,\n","                alpha,\n","                beta,\n","                gamma,\n","                delta,\n","            ) = compute_loss(\n","                reconstructed_imgs_list,\n","                inputs,\n","                mu,\n","                logvar,\n","                predicted_labels,\n","                labels,\n","                domain_predictions,\n","                domain_labels,\n","                lambda pred, target: mixup_criterion(\n","                    clf_loss_fn, pred, labels_a, labels_b, lam\n","                ),\n","                domain_loss_fn,\n","                epoch,\n","                num_epochs,\n","                balancer,\n","            )\n","\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","            \n","            torch.nn.utils.clip_grad_norm_(params, max_norm=1.0)\n","\n","            running_loss += loss.item() * inputs.size(0)\n","            running_recon_loss += recon_loss * inputs.size(0)\n","            running_clf_loss += clf_loss * inputs.size(0)\n","            running_kl_loss += kl_loss * inputs.size(0)\n","            total_samples += inputs.size(0)\n","\n","        avg_loss = running_loss / total_samples\n","        avg_recon_loss = running_recon_loss / total_samples\n","        avg_clf_loss = running_clf_loss / total_samples\n","        avg_kl_loss = running_kl_loss / total_samples\n","\n","        print(\n","            f\"Epoch {epoch + 1}, Loss: {avg_loss:.4f}, Recon: {avg_recon_loss:.4f}, Clf: {avg_clf_loss:.4f}, KL: {avg_kl_loss:.4f} Domain: {domain_loss:.4f}\"\n","        )\n","        print(\n","            f\"Weights - Alpha: {alpha:.4f}, Beta: {beta:.4f}, Gamma: {gamma:.4f}, Delta: {delta:.4f}\"\n","        )\n","\n","        # Validation\n","        encoder.eval()\n","        classifier.eval()\n","        for domain in train_domains:\n","            decoders[domain].eval()\n","\n","        val_running_loss = 0.0\n","        with torch.no_grad():\n","            for inputs, labels in tqdm(val_loader, desc=\"Validating\"):\n","                inputs, labels = inputs.to(device), labels.to(device)\n","\n","                mu, logvar = encoder(inputs)\n","                z = reparameterize(mu, logvar)\n","\n","                reconstructed_imgs_list = []\n","                for domain in train_domains:\n","                    domain_label = torch.tensor(\n","                        [domain_to_idx[domain]] * inputs.size(0), device=device\n","                    )\n","                    reconstructed_imgs = decoders[domain](z, domain_label)\n","                    reconstructed_imgs_list.append(reconstructed_imgs)\n","\n","                predicted_labels = classifier(z)\n","\n","                val_loss, _, _, _, _, _, _, _, _ = compute_loss(\n","                    reconstructed_imgs_list,\n","                    inputs,\n","                    mu,\n","                    logvar,\n","                    predicted_labels,\n","                    labels,\n","                    domain_predictions,\n","                    domain_labels,\n","                    clf_loss_fn,\n","                    domain_loss_fn,\n","                    epoch,\n","                    num_epochs,\n","                    balancer,\n","                )\n","                val_running_loss += val_loss.item()\n","\n","        avg_val_loss = val_running_loss / len(val_loader)\n","        print(f\"Validation Loss: {avg_val_loss:.4f}\")\n","\n","        # Đánh giá trên tập test\n","        if (epoch + 1) % 3 == 0:\n","            print(\n","                f\"--- Evaluating on Test Domain ({test_domain}) at Epoch {epoch + 1} ---\"\n","            )\n","            test_accuracy, test_loss, domain_accuracy = evaluate_model(\n","                encoder, classifier, domain_classifier, test_loader, device\n","            )\n","            print(f\"Test Accuracy: {test_accuracy:.2f}%, Test Loss: {test_loss:.4f}, Domain Accuracy: {domain_accuracy:.2f}%\")\n","\n","            # Save best model based on test accuracy\n","            if test_accuracy > best_test_accuracy:\n","                best_test_accuracy = test_accuracy\n","                best_model[\"encoder\"] = copy.deepcopy(encoder.state_dict())\n","                best_model[\"decoders\"] = {\n","                    domain: copy.deepcopy(decoder.state_dict())\n","                    for domain, decoder in decoders.items()\n","                }\n","                best_model[\"classifier\"] = copy.deepcopy(classifier.state_dict())\n","                best_model[\"domain_classifier\"] = copy.deepcopy(domain_classifier.state_dict())\n","                print(\n","                    f\"New best model saved with test accuracy: {best_test_accuracy:.2f}%\"\n","                )\n","\n","        # Early stopping based on validation loss\n","        if avg_val_loss < best_loss:\n","            best_loss = avg_val_loss\n","            patience_counter = 0\n","        else:\n","            patience_counter += 1\n","            if patience_counter >= patience:\n","                print(f\"Early stopping triggered after {epoch + 1} epochs\")\n","                break\n","\n","        scheduler.step(avg_val_loss)\n","\n","    # Load best model\n","    encoder.load_state_dict(best_model[\"encoder\"])\n","    for domain, state_dict in best_model[\"decoders\"].items():\n","        decoders[domain].load_state_dict(state_dict)\n","    classifier.load_state_dict(best_model[\"classifier\"])\n","    domain_classifier.load_state_dict(best_model[\"domain_classifier\"])\n","\n","    print(f\"Training completed. Best test accuracy: {best_test_accuracy:.2f}%\")\n","\n","    return encoder, decoders, classifier"]},{"cell_type":"code","execution_count":43,"metadata":{"_cell_guid":"0c32e3d7-7e0b-4c05-b103-4283e23a4537","_uuid":"429d1f1c-58e6-4417-99fc-87659a68d4a4","collapsed":false,"execution":{"iopub.execute_input":"2024-10-09T11:00:38.866521Z","iopub.status.busy":"2024-10-09T11:00:38.866172Z","iopub.status.idle":"2024-10-09T11:00:38.878245Z","shell.execute_reply":"2024-10-09T11:00:38.877490Z","shell.execute_reply.started":"2024-10-09T11:00:38.866480Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["def evaluate_model(encoder, classifier, domain_classifier, dataloader, device):\n","    encoder.eval()\n","    classifier.eval()\n","    domain_classifier.eval()\n","    correct = 0\n","    total = 0\n","    running_loss = 0.0\n","    domain_correct = 0\n","    clf_loss_fn = nn.CrossEntropyLoss()\n","    domain_loss_fn = nn.BCEWithLogitsLoss()\n","\n","    with torch.no_grad():\n","        for inputs, labels in dataloader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            domain_labels = torch.ones(inputs.size(0), 1).to(\n","                device\n","            )  # 1 for target domain\n","\n","            mu, logvar = encoder(inputs)\n","            z = reparameterize(mu, logvar)\n","            outputs = classifier(z)\n","            domain_outputs = domain_classifier(z)\n","\n","            loss = clf_loss_fn(outputs, labels)\n","            running_loss += loss.item() * inputs.size(0)\n","\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","            domain_pred = (domain_outputs > 0.5).float()\n","            domain_correct += (domain_pred == domain_labels).sum().item()\n","\n","    accuracy = 100 * correct / total\n","    avg_loss = running_loss / total\n","    domain_accuracy = 100 * domain_correct / total\n","    return accuracy, avg_loss, domain_accuracy\n"]},{"cell_type":"code","execution_count":44,"metadata":{"_cell_guid":"cb4e367a-618c-4f58-afb1-f5f0c8bb4b0f","_uuid":"daa6ce59-bd81-4207-9e8e-eac6313bc129","collapsed":false,"execution":{"iopub.execute_input":"2024-10-09T11:00:38.879518Z","iopub.status.busy":"2024-10-09T11:00:38.879221Z","iopub.status.idle":"2024-10-09T11:00:59.174147Z","shell.execute_reply":"2024-10-09T11:00:59.172680Z","shell.execute_reply.started":"2024-10-09T11:00:38.879488Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Using device: cuda\n","Training model with progressive domain adaptation\n","Number of epochs: 150\n","Patience: 10\n","Train domains: ['art_painting', 'cartoon', 'sketch']\n","Test domain: photo\n","Device: cuda\n","Number of training samples: 832\n","Number of validation samples: 7489\n","Number of test samples: 1670\n","Epoch 1/150\n"]},{"name":"stderr","output_type":"stream","text":["Training:   0%|          | 0/52 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["domain predictions tensor([[ 0.0439],\n","        [ 0.1539],\n","        [-0.2274],\n","        [-0.4488],\n","        [-0.0793],\n","        [ 0.0304],\n","        [-0.1193],\n","        [ 0.1158],\n","        [ 0.1734],\n","        [-0.3065],\n","        [-0.0356],\n","        [ 0.2071],\n","        [-0.1566],\n","        [-0.1367],\n","        [-0.2794],\n","        [-0.2330]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training:   2%|▏         | 1/52 [00:00<00:39,  1.28it/s]"]},{"name":"stdout","output_type":"stream","text":["domain predictions tensor([[-0.9284],\n","        [-0.2196],\n","        [ 0.3168],\n","        [ 0.0987],\n","        [-0.0696],\n","        [-0.1328],\n","        [ 0.1236],\n","        [ 0.0944],\n","        [-0.0679],\n","        [ 0.0611],\n","        [-0.1940],\n","        [ 0.3545],\n","        [-0.2802],\n","        [ 0.2723],\n","        [ 0.0762],\n","        [-0.0970]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training:   4%|▍         | 2/52 [00:01<00:37,  1.35it/s]"]},{"name":"stdout","output_type":"stream","text":["domain predictions tensor([[-0.4311],\n","        [-0.0381],\n","        [-0.0926],\n","        [-0.2520],\n","        [-0.5113],\n","        [ 0.1155],\n","        [-0.0547],\n","        [-0.1290],\n","        [-0.1395],\n","        [-0.2754],\n","        [ 0.0820],\n","        [-0.1608],\n","        [-0.0220],\n","        [-0.0949],\n","        [-0.3521],\n","        [ 0.0710]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training:   6%|▌         | 3/52 [00:02<00:36,  1.35it/s]"]},{"name":"stdout","output_type":"stream","text":["domain predictions tensor([[-0.4773],\n","        [ 0.4708],\n","        [-0.1303],\n","        [-0.1346],\n","        [-0.1004],\n","        [ 0.2344],\n","        [-0.0475],\n","        [-0.2334],\n","        [-0.1991],\n","        [-1.0036],\n","        [-0.2289],\n","        [ 0.4647],\n","        [ 0.2541],\n","        [-0.1496],\n","        [ 0.1841],\n","        [-0.1302]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training:   8%|▊         | 4/52 [00:02<00:35,  1.37it/s]"]},{"name":"stdout","output_type":"stream","text":["domain predictions tensor([[ 0.3128],\n","        [ 0.0053],\n","        [-0.0914],\n","        [-0.0499],\n","        [-0.1627],\n","        [ 0.2984],\n","        [ 0.2198],\n","        [-0.3507],\n","        [ 0.2543],\n","        [ 0.0147],\n","        [ 0.1901],\n","        [-0.5297],\n","        [-0.4948],\n","        [-0.0709],\n","        [-0.1253],\n","        [-0.0855]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training:  10%|▉         | 5/52 [00:03<00:34,  1.37it/s]"]},{"name":"stdout","output_type":"stream","text":["domain predictions tensor([[-0.1570],\n","        [-0.4795],\n","        [-0.3049],\n","        [-0.0809],\n","        [ 0.3754],\n","        [-0.1718],\n","        [ 0.1736],\n","        [ 0.2498],\n","        [ 0.0696],\n","        [-0.1413],\n","        [ 0.0778],\n","        [-0.5950],\n","        [ 0.0954],\n","        [ 0.1709],\n","        [-0.8241],\n","        [ 0.1475]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training:  12%|█▏        | 6/52 [00:04<00:33,  1.37it/s]"]},{"name":"stdout","output_type":"stream","text":["domain predictions tensor([[-0.0875],\n","        [-0.3253],\n","        [ 0.0970],\n","        [ 0.7079],\n","        [-0.2958],\n","        [ 0.2771],\n","        [ 0.3537],\n","        [ 0.1329],\n","        [-0.0330],\n","        [ 0.1374],\n","        [-0.0254],\n","        [-0.2657],\n","        [-0.0303],\n","        [ 0.1240],\n","        [-0.1484],\n","        [-0.3071]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training:  13%|█▎        | 7/52 [00:05<00:32,  1.37it/s]"]},{"name":"stdout","output_type":"stream","text":["domain predictions tensor([[ 0.2610],\n","        [ 0.1348],\n","        [-0.0796],\n","        [ 0.1843],\n","        [-0.1253],\n","        [-0.2523],\n","        [ 0.4802],\n","        [-0.4105],\n","        [-0.3478],\n","        [-0.1046],\n","        [ 0.6479],\n","        [-0.3465],\n","        [-0.1650],\n","        [ 0.0070],\n","        [-0.1200],\n","        [ 0.0656]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training:  15%|█▌        | 8/52 [00:05<00:32,  1.36it/s]"]},{"name":"stdout","output_type":"stream","text":["domain predictions tensor([[ 0.5360],\n","        [-0.1060],\n","        [-0.1667],\n","        [ 0.1929],\n","        [-0.0918],\n","        [ 0.6101],\n","        [-0.0099],\n","        [ 0.0896],\n","        [-0.1647],\n","        [-0.2075],\n","        [-0.1051],\n","        [-0.4203],\n","        [-0.3324],\n","        [-0.1905],\n","        [ 0.0089],\n","        [-0.3192]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training:  17%|█▋        | 9/52 [00:06<00:31,  1.36it/s]"]},{"name":"stdout","output_type":"stream","text":["domain predictions tensor([[-0.8141],\n","        [ 0.0406],\n","        [-0.0250],\n","        [ 0.2235],\n","        [-0.3825],\n","        [-0.4282],\n","        [ 0.1551],\n","        [-0.1742],\n","        [-0.3457],\n","        [-0.1173],\n","        [-0.1648],\n","        [ 0.0209],\n","        [ 0.4001],\n","        [-0.0269],\n","        [-0.0149],\n","        [-0.0093]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training:  19%|█▉        | 10/52 [00:07<00:30,  1.36it/s]"]},{"name":"stdout","output_type":"stream","text":["domain predictions tensor([[ 0.0261],\n","        [ 0.3975],\n","        [ 0.0359],\n","        [-0.1767],\n","        [ 0.2031],\n","        [-0.2450],\n","        [-0.0590],\n","        [-0.0945],\n","        [-0.2258],\n","        [-0.0568],\n","        [-0.0812],\n","        [-0.6195],\n","        [ 0.1333],\n","        [-0.3028],\n","        [-0.3345],\n","        [ 0.2901]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training:  21%|██        | 11/52 [00:08<00:29,  1.37it/s]"]},{"name":"stdout","output_type":"stream","text":["domain predictions tensor([[-0.1025],\n","        [-0.0713],\n","        [ 0.0090],\n","        [ 0.1236],\n","        [ 0.0385],\n","        [ 0.4355],\n","        [-0.0805],\n","        [ 0.0976],\n","        [-0.0887],\n","        [ 0.2006],\n","        [-0.1410],\n","        [ 0.2026],\n","        [ 0.0670],\n","        [ 0.0523],\n","        [ 0.0760],\n","        [-0.0147]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training:  23%|██▎       | 12/52 [00:08<00:29,  1.37it/s]"]},{"name":"stdout","output_type":"stream","text":["domain predictions tensor([[ 0.0119],\n","        [-0.0494],\n","        [ 0.0987],\n","        [-0.3474],\n","        [-0.3411],\n","        [-0.1155],\n","        [-0.0866],\n","        [ 0.0230],\n","        [ 0.1624],\n","        [-0.1040],\n","        [ 0.4110],\n","        [-0.0535],\n","        [ 0.0217],\n","        [-0.0269],\n","        [ 0.5047],\n","        [ 0.5321]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training:  25%|██▌       | 13/52 [00:09<00:28,  1.36it/s]"]},{"name":"stdout","output_type":"stream","text":["domain predictions tensor([[-0.1041],\n","        [-0.0744],\n","        [-0.3963],\n","        [-0.3789],\n","        [-0.0649],\n","        [ 0.1552],\n","        [-0.0893],\n","        [-0.2485],\n","        [-0.4770],\n","        [ 0.3260],\n","        [-0.0558],\n","        [ 0.0552],\n","        [ 0.5875],\n","        [-0.4078],\n","        [ 0.0563],\n","        [-0.2464]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training:  27%|██▋       | 14/52 [00:10<00:27,  1.37it/s]"]},{"name":"stdout","output_type":"stream","text":["domain predictions tensor([[ 0.0084],\n","        [ 0.0737],\n","        [-0.1374],\n","        [-0.1678],\n","        [ 0.1955],\n","        [-0.2193],\n","        [-0.0855],\n","        [-0.2667],\n","        [-0.2982],\n","        [-0.4637],\n","        [-0.3247],\n","        [-0.0298],\n","        [ 0.7572],\n","        [ 0.0015],\n","        [ 0.1387],\n","        [ 0.1102]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training:  29%|██▉       | 15/52 [00:11<00:27,  1.36it/s]"]},{"name":"stdout","output_type":"stream","text":["domain predictions tensor([[ 0.0428],\n","        [-0.6070],\n","        [ 0.5845],\n","        [-0.4517],\n","        [-0.2037],\n","        [-0.1021],\n","        [-0.0438],\n","        [ 0.2342],\n","        [-0.0598],\n","        [ 0.1268],\n","        [-0.1753],\n","        [-0.2773],\n","        [-0.1051],\n","        [ 0.0782],\n","        [-0.1589],\n","        [-0.4223]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training:  31%|███       | 16/52 [00:11<00:26,  1.36it/s]"]},{"name":"stdout","output_type":"stream","text":["domain predictions tensor([[ 0.2856],\n","        [-0.2786],\n","        [-0.4168],\n","        [-0.2848],\n","        [ 0.2392],\n","        [ 0.1052],\n","        [-0.2449],\n","        [-0.2040],\n","        [ 0.0621],\n","        [ 0.1092],\n","        [-0.1049],\n","        [-0.5002],\n","        [-0.1030],\n","        [ 0.0495],\n","        [-0.1351],\n","        [-0.2540]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training:  33%|███▎      | 17/52 [00:12<00:25,  1.36it/s]"]},{"name":"stdout","output_type":"stream","text":["domain predictions tensor([[-0.2340],\n","        [-0.2177],\n","        [-0.0961],\n","        [-0.1419],\n","        [ 0.1652],\n","        [-0.2511],\n","        [-0.4240],\n","        [-0.1598],\n","        [ 0.2596],\n","        [ 0.1529],\n","        [ 0.0675],\n","        [-1.4376],\n","        [-0.3648],\n","        [-0.0170],\n","        [ 0.0709],\n","        [ 0.2475]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training:  35%|███▍      | 18/52 [00:13<00:25,  1.36it/s]"]},{"name":"stdout","output_type":"stream","text":["domain predictions tensor([[-0.3366],\n","        [-0.0379],\n","        [-0.4659],\n","        [-0.2282],\n","        [ 0.2607],\n","        [ 0.0323],\n","        [ 0.2288],\n","        [-0.4854],\n","        [-0.4098],\n","        [-0.2662],\n","        [-0.3131],\n","        [-0.3707],\n","        [-0.0648],\n","        [ 0.3891],\n","        [ 0.0522],\n","        [ 0.0233]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training:  37%|███▋      | 19/52 [00:13<00:24,  1.34it/s]"]},{"name":"stdout","output_type":"stream","text":["domain predictions tensor([[ 0.0289],\n","        [-0.1465],\n","        [ 0.0533],\n","        [-0.4699],\n","        [-0.2300],\n","        [-0.0651],\n","        [ 0.1887],\n","        [-0.3409],\n","        [-0.2252],\n","        [-0.2868],\n","        [-0.4400],\n","        [-0.2598],\n","        [-0.1428],\n","        [ 0.1102],\n","        [-0.2456],\n","        [ 0.2204]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training:  38%|███▊      | 20/52 [00:14<00:24,  1.32it/s]"]},{"name":"stdout","output_type":"stream","text":["domain predictions tensor([[-0.2346],\n","        [-0.7421],\n","        [ 0.0112],\n","        [ 0.0670],\n","        [ 0.0909],\n","        [ 0.3031],\n","        [-0.2629],\n","        [ 0.0401],\n","        [ 0.0720],\n","        [-0.1333],\n","        [ 0.3835],\n","        [ 0.3177],\n","        [-0.2549],\n","        [-0.1581],\n","        [ 0.1449],\n","        [-0.0129]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training:  40%|████      | 21/52 [00:15<00:23,  1.33it/s]"]},{"name":"stdout","output_type":"stream","text":["domain predictions tensor([[-0.0381],\n","        [ 0.0189],\n","        [-0.0540],\n","        [-0.1905],\n","        [-0.0513],\n","        [ 0.1089],\n","        [ 0.0770],\n","        [-0.0947],\n","        [ 0.0296],\n","        [ 0.0536],\n","        [-0.1913],\n","        [-0.1153],\n","        [ 0.2814],\n","        [-0.2379],\n","        [ 0.3405],\n","        [-0.2129]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training:  42%|████▏     | 22/52 [00:16<00:22,  1.33it/s]"]},{"name":"stdout","output_type":"stream","text":["domain predictions tensor([[-0.3295],\n","        [ 0.4537],\n","        [-0.7915],\n","        [-0.2695],\n","        [-0.0319],\n","        [-0.0956],\n","        [-0.2650],\n","        [ 0.2524],\n","        [-0.2404],\n","        [-0.1075],\n","        [-0.0422],\n","        [-0.3652],\n","        [ 0.0642],\n","        [ 0.1111],\n","        [-0.3112],\n","        [ 0.1236]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training:  44%|████▍     | 23/52 [00:16<00:21,  1.35it/s]"]},{"name":"stdout","output_type":"stream","text":["domain predictions tensor([[ 0.0389],\n","        [-0.0530],\n","        [ 0.1820],\n","        [-0.5159],\n","        [-0.0735],\n","        [-0.2273],\n","        [ 0.2548],\n","        [ 0.0753],\n","        [ 0.0270],\n","        [ 0.3885],\n","        [-0.4079],\n","        [-0.3667],\n","        [ 0.4055],\n","        [-0.0520],\n","        [-0.4346],\n","        [-0.3889]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training:  46%|████▌     | 24/52 [00:17<00:20,  1.34it/s]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[44], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m train_loader, val_loader, test_loader \u001b[38;5;241m=\u001b[39m get_dataloader(DATA_PATH, train_domains, test_domain)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m encoder, decoders, classifier \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model_progressive\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclassifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdomain_classifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_domains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_domain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinal evaluation on test domain: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_domain\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     49\u001b[0m test_accuracy, test_loss, domain_accuracy \u001b[38;5;241m=\u001b[39m evaluate_model(\n\u001b[1;32m     50\u001b[0m     encoder, classifier, domain_classifier, test_loader, device\n\u001b[1;32m     51\u001b[0m )\n","Cell \u001b[0;32mIn[42], line 66\u001b[0m, in \u001b[0;36mtrain_model_progressive\u001b[0;34m(encoder, decoders, classifier, domain_classifier, train_domains, test_domain, train_loader, val_loader, test_loader, optimizer, scheduler, num_epochs, device, patience)\u001b[0m\n\u001b[1;32m     59\u001b[0m domain_labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(inputs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m     60\u001b[0m     device\n\u001b[1;32m     61\u001b[0m )  \u001b[38;5;66;03m# 0 for source domain\u001b[39;00m\n\u001b[1;32m     62\u001b[0m inputs, labels_a, labels_b, lam \u001b[38;5;241m=\u001b[39m mixup_data(\n\u001b[1;32m     63\u001b[0m     inputs, labels, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 66\u001b[0m mu, logvar \u001b[38;5;241m=\u001b[39m \u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m z \u001b[38;5;241m=\u001b[39m reparameterize(mu, logvar)\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# Forward pass through domain classifier with gradient reversal\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[0;32mIn[35], line 30\u001b[0m, in \u001b[0;36mEncoder.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;66;03m# Pass input through EfficientNet feature extractor\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mefficientnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mefficientnet\u001b[38;5;241m.\u001b[39mavgpool(features)\n\u001b[1;32m     32\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mflatten(x, \u001b[38;5;241m1\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 219\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 219\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/models/efficientnet.py:164\u001b[0m, in \u001b[0;36mMBConv.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 164\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_res_connect:\n\u001b[1;32m    166\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstochastic_depth(result)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 219\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 219\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:156\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrack_running_stats:\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;66;03m# TODO: if statement only here to tell the jit to skip emitting this when it is None\u001b[39;00m\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_batches_tracked \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[0;32m--> 156\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_batches_tracked\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmomentum \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# use cumulative moving average\u001b[39;00m\n\u001b[1;32m    158\u001b[0m             exponential_average_factor \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_batches_tracked)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# Main training and evaluation script\n","DATA_PATH = \"/kaggle/input/pacs-dataset/kfold\"\n","latent_dim = 256\n","num_classes = 7\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")\n","\n","train_domains = [\"art_painting\", \"cartoon\", \"sketch\"]\n","test_domain = \"photo\"\n","all_domains = train_domains + [test_domain]\n","\n","# Initialize models\n","encoder = Encoder(latent_dim).to(device)\n","decoders = {domain: Decoder(latent_dim, len(train_domains)).to(device) for domain in train_domains}\n","classifier = Classifier(latent_dim, num_classes).to(device)\n","domain_classifier = DomainClassifier(latent_dim).to(device)\n","\n","# Optimizer and Scheduler\n","params = list(encoder.parameters()) + list(classifier.parameters())\n","for decoder in decoders.values():\n","    params += list(decoder.parameters())\n","\n","optimizer = optim.AdamW(params, lr=5e-4, weight_decay=1e-3) \n","scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2, eta_min=1e-6)\n","num_epochs = 150  # Tăng số epoch\n","\n","# Get dataloaders\n","train_loader, val_loader, test_loader = get_dataloader(DATA_PATH, train_domains, test_domain)\n","\n","# Train model\n","encoder, decoders, classifier = train_model_progressive(\n","    encoder,\n","    decoders,\n","    classifier,\n","    domain_classifier,\n","    train_domains,\n","    test_domain,\n","    train_loader,\n","    val_loader,\n","    test_loader,\n","    optimizer,\n","    scheduler,\n","    num_epochs,\n","    device=device,\n","    patience=10,\n",")\n","\n","print(f\"Final evaluation on test domain: {test_domain}\")\n","test_accuracy, test_loss, domain_accuracy = evaluate_model(\n","    encoder, classifier, domain_classifier, test_loader, device\n",")\n","print(f\"Test Accuracy: {test_accuracy:.2f}%, Test Loss: {test_loss:.4f}, Domain Accuracy: {domain_accuracy:.2f}%\")\n","# Final evaluation on the test domain\n","print(f\"Final evaluation on test domain: {test_domain}\")\n","test_accuracy, test_loss, domain_accuracy = evaluate_model(\n","    encoder, classifier, domain_classifier, test_loader, device\n",")\n","print(f\"Test Accuracy: {test_accuracy:.2f}%, Test Loss: {test_loss:.4f} Domain Accuracy: {domain_accuracy:.2f}%\")"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":5815134,"sourceId":9545143,"sourceType":"datasetVersion"}],"dockerImageVersionId":30787,"isGpuEnabled":true,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}

{"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9545143,"sourceType":"datasetVersion","datasetId":5815134}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, models\nfrom tqdm import tqdm\nfrom PIL import Image\nimport os\nimport torch.nn.functional as F\nfrom torch.nn.modules.loss import _WeightedLoss\nfrom sklearn.model_selection import train_test_split\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2","metadata":{"_cell_guid":"4f436e96-ef21-4124-b43a-f3a7eb31b6cf","_uuid":"161a57a5-c9a7-47a3-87cd-6d351a6cdb92","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-10-04T21:33:19.490390Z","iopub.execute_input":"2024-10-04T21:33:19.490756Z","iopub.status.idle":"2024-10-04T21:33:19.497357Z","shell.execute_reply.started":"2024-10-04T21:33:19.490725Z","shell.execute_reply":"2024-10-04T21:33:19.496260Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"import random\nimport numpy as np\n\ndef set_random_seeds(seed_value=42):\n    torch.manual_seed(seed_value)\n    torch.cuda.manual_seed(seed_value)\n    torch.cuda.manual_seed_all(seed_value)  # if you are using multi-GPU.\n    np.random.seed(seed_value)  # Numpy module.\n    random.seed(seed_value)  # Python random module.\n    torch.backends.cudnn.benchmark = False\n    torch.backends.cudnn.deterministic = True\n\nset_random_seeds()","metadata":{"_cell_guid":"94b1820c-4753-470c-8f95-aab713e66535","_uuid":"013a8b5e-7432-4915-a2c0-9a8f5daaaff1","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-10-04T21:33:19.498996Z","iopub.execute_input":"2024-10-04T21:33:19.499372Z","iopub.status.idle":"2024-10-04T21:33:19.512039Z","shell.execute_reply.started":"2024-10-04T21:33:19.499338Z","shell.execute_reply":"2024-10-04T21:33:19.511177Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"class PACSDataset(Dataset):\n    def __init__(self, root_dir, domains, transform=None):\n        self.root_dir = root_dir\n        self.domains = domains\n        self.transform = transform\n        self.images = []\n        self.labels = []\n        self._load_images_labels()\n\n    def _load_images_labels(self):\n        for domain in self.domains:\n            domain_dir = os.path.join(self.root_dir, domain)\n            classes = sorted(\n                [\n                    d\n                    for d in os.listdir(domain_dir)\n                    if os.path.isdir(os.path.join(domain_dir, d))\n                ]\n            )\n\n            for label, class_name in enumerate(classes):\n                class_dir = os.path.join(domain_dir, class_name)\n                for image_name in os.listdir(class_dir):\n                    if image_name.endswith((\".png\", \".jpg\", \".jpeg\")):\n                        self.images.append(os.path.join(class_dir, image_name))\n                        self.labels.append(label)\n\n    def __len__(self):\n        return len(self.images)\n\n    def __getitem__(self, idx):\n        image_path = self.images[idx]\n        image = Image.open(image_path).convert(\"RGB\")\n        label = self.labels[idx]\n\n        if self.transform:\n            image = self.transform(image)\n\n        return image, label\n\n\ndef get_transform():\n    return transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomRotation(10),\n        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n        transforms.RandomErasing(p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3), value=0),\n    ])","metadata":{"execution":{"iopub.status.busy":"2024-10-04T21:33:19.513163Z","iopub.execute_input":"2024-10-04T21:33:19.513549Z","iopub.status.idle":"2024-10-04T21:33:19.527960Z","shell.execute_reply.started":"2024-10-04T21:33:19.513505Z","shell.execute_reply":"2024-10-04T21:33:19.527242Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"def get_dataloader(\n    root_dir,\n    domains,\n    batch_size=32,\n    train_size=0.7,\n    val_size=0.15,\n    test_size=0.15,\n    random_seed=42,\n):\n    # Ensure the sizes sum to 1\n    assert train_size + val_size + test_size == 1.0\n\n    # Load all image paths and their corresponding labels from all domains\n    image_paths = []\n    labels = []\n    for domain in domains:\n        domain_dir = os.path.join(root_dir, domain)\n        classes = sorted(\n            [\n                d\n                for d in os.listdir(domain_dir)\n                if os.path.isdir(os.path.join(domain_dir, d))\n            ]\n        )\n\n        for label, class_name in enumerate(classes):\n            class_dir = os.path.join(domain_dir, class_name)\n            for image_name in os.listdir(class_dir):\n                if image_name.endswith((\".png\", \".jpg\", \".jpeg\")):\n                    image_paths.append(os.path.join(class_dir, image_name))\n                    labels.append(label)\n\n    # Split the combined dataset into train, val, and test\n    train_paths, temp_paths, train_labels, temp_labels = train_test_split(\n        image_paths,\n        labels,\n        train_size=train_size,\n        stratify=labels,\n        random_state=random_seed,\n    )\n    val_paths, test_paths, val_labels, test_labels = train_test_split(\n        temp_paths,\n        temp_labels,\n        train_size=val_size / (val_size + test_size),\n        stratify=temp_labels,\n        random_state=random_seed,\n    )\n\n    # Create datasets\n    train_dataset = PACSDataset(root_dir, domains, transform=get_transform())\n    train_dataset.images = train_paths\n    train_dataset.labels = train_labels\n\n    val_dataset = PACSDataset(root_dir, domains, transform=get_transform())\n    val_dataset.images = val_paths\n    val_dataset.labels = val_labels\n\n    test_dataset = PACSDataset(root_dir, domains, transform=get_transform())\n    test_dataset.images = test_paths\n    test_dataset.labels = test_labels\n\n    # Create DataLoaders\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n\n    return train_loader, val_loader, test_loader","metadata":{"_cell_guid":"633a724d-b68c-45bb-ab3c-e88e9115dbbc","_uuid":"9cc659f6-3f5a-4ddd-96c2-737a8c49e42a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-10-04T21:33:19.529591Z","iopub.execute_input":"2024-10-04T21:33:19.529881Z","iopub.status.idle":"2024-10-04T21:33:19.545219Z","shell.execute_reply.started":"2024-10-04T21:33:19.529850Z","shell.execute_reply":"2024-10-04T21:33:19.544241Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"# Define Encoder, Decoder, Classifier\nclass Encoder(nn.Module):\n    def __init__(self, latent_dim):\n        super(Encoder, self).__init__()\n\n        # Sử dụng EfficientNet-B1\n        self.efficientnet = models.efficientnet_b1(weights=models.EfficientNet_B1_Weights.IMAGENET1K_V1)\n\n        # Freeze EfficientNet layers\n        for param in self.efficientnet.parameters():\n            param.requires_grad = False\n\n        # Lấy số features từ lớp cuối cùng của EfficientNet-B1\n        in_features = self.efficientnet.classifier[1].in_features\n\n        # Attention mechanism\n        self.attention = nn.Sequential(\n            nn.Linear(in_features, in_features // 16),\n            nn.ReLU(),\n            nn.Linear(in_features // 16, in_features),\n            nn.Sigmoid(),\n        )\n\n        # Mean (mu) and log-variance (logvar) layers\n        self.fc_mu = nn.Linear(in_features, latent_dim)\n        self.fc_logvar = nn.Linear(in_features, latent_dim)\n\n        self.dropout = nn.Dropout(0.5)  # Add dropout\n\n    def forward(self, x):\n        # Pass input through EfficientNet feature extractor\n        features = self.efficientnet.features(x)\n        x = self.efficientnet.avgpool(features)\n        x = torch.flatten(x, 1)\n\n        x = self.dropout(x)  # Apply dropout\n\n        # Apply attention\n        attention_weights = self.attention(x)\n        x = x * attention_weights\n\n        # Compute mu and logvar\n        mu = self.fc_mu(x)\n        logvar = self.fc_logvar(x)\n        return mu, logvar\n\n\nclass ResidualBlock(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(ResidualBlock, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n\n        self.shortcut = nn.Sequential()\n        if in_channels != out_channels:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_channels, out_channels, kernel_size=1),\n                nn.BatchNorm2d(out_channels),\n            )\n\n    def forward(self, x):\n        residual = x\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n        out += self.shortcut(residual)\n        out = F.relu(out)\n        return out\n\n\nclass Decoder(nn.Module):\n    def __init__(self, latent_dim, num_domains):\n        super(Decoder, self).__init__()\n\n        self.domain_embedding = nn.Embedding(num_domains, latent_dim)\n\n        self.fc = nn.Linear(latent_dim, 512 * 7 * 7)\n\n        self.decoder = nn.Sequential(\n            ResidualBlock(512, 256),\n            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(),\n            ResidualBlock(128, 128),\n            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            ResidualBlock(64, 64),\n            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),\n            nn.BatchNorm2d(32),\n            nn.ReLU(),\n            nn.ConvTranspose2d(32, 16, kernel_size=4, stride=2, padding=1),\n            nn.BatchNorm2d(16),\n            nn.ReLU(),\n            nn.ConvTranspose2d(16, 3, kernel_size=4, stride=2, padding=1),\n            nn.Tanh()  # Thêm Tanh để đảm bảo đầu ra trong khoảng [-1, 1]\n        )\n\n        # Attention mechanism\n        self.attention = nn.Sequential(nn.Conv2d(3, 1, kernel_size=1), nn.Sigmoid())\n\n    def forward(self, z, domain_label):\n        domain_embed = self.domain_embedding(domain_label)\n        z = z + domain_embed\n\n        x = self.fc(z)\n        x = x.view(-1, 512, 7, 7)\n        x = self.decoder(x)\n\n        # Apply attention\n        attention_map = self.attention(x)\n        x = x * attention_map\n\n        return x\n\n\nclass Classifier(nn.Module):\n    def __init__(self, latent_dim, num_classes):\n        super(Classifier, self).__init__()\n        self.fc = nn.Linear(latent_dim, num_classes)\n        self.dropout = nn.Dropout(0.5)\n\n    def forward(self, z):\n        z = self.dropout(z)\n        return self.fc(z)","metadata":{"_cell_guid":"77b09e73-481d-48f2-be3d-49a15d8c6777","_uuid":"258e95c8-5d7d-4888-a00d-0a5e99aaa736","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-10-04T21:33:19.624425Z","iopub.execute_input":"2024-10-04T21:33:19.624756Z","iopub.status.idle":"2024-10-04T21:33:19.648339Z","shell.execute_reply.started":"2024-10-04T21:33:19.624707Z","shell.execute_reply":"2024-10-04T21:33:19.647413Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"class LabelSmoothingLoss(_WeightedLoss):\n    def __init__(self, weight=None, reduction=\"mean\", smoothing=0.0):\n        super().__init__(weight=weight, reduction=reduction)\n        self.smoothing = smoothing\n        self.weight = weight\n        self.reduction = reduction\n\n    def k_one_hot(self, targets: torch.Tensor, n_classes: int, smoothing=0.0):\n        with torch.no_grad():\n            targets = (\n                torch.empty(size=(targets.size(0), n_classes), device=targets.device)\n                .fill_(smoothing / (n_classes - 1))\n                .scatter_(1, targets.data.unsqueeze(1), 1.0 - smoothing)\n            )\n        return targets\n\n    def reduce_loss(self, loss):\n        return (\n            loss.mean()\n            if self.reduction == \"mean\"\n            else loss.sum() if self.reduction == \"sum\" else loss\n        )\n\n    def forward(self, inputs, targets):\n        assert 0 <= self.smoothing < 1\n\n        targets = self.k_one_hot(targets, inputs.size(-1), self.smoothing)\n        log_preds = F.log_softmax(inputs, -1)\n\n        if self.weight is not None:\n            log_preds = log_preds * self.weight.unsqueeze(0)\n\n        return self.reduce_loss(-(targets * log_preds).sum(dim=-1))\n\nclass DynamicWeightBalancer:\n    def __init__(self, init_alpha=0.5, init_beta=2.0, init_gamma=0.1, patience=5, scaling_factor=0.8):\n        self.alpha = init_alpha  # Reconstruction loss weight\n        self.beta = init_beta    # Classification loss weight\n        self.gamma = init_gamma  # KL divergence weight\n        self.patience = patience\n        self.scaling_factor = scaling_factor\n        self.best_loss = float('inf')\n        self.counter = 0\n\n    def update(self, current_loss, recon_loss, clf_loss, kl_loss):\n        if current_loss < self.best_loss:\n            self.best_loss = current_loss\n            self.counter = 0\n        else:\n            self.counter += 1\n\n        if self.counter >= self.patience:\n            self.counter = 0\n            # Increase classification weight and decrease others\n            self.beta /= self.scaling_factor\n            self.alpha *= self.scaling_factor\n            self.gamma *= self.scaling_factor\n\n        # Ensure classification loss weight is always significantly larger\n        total_weight = self.alpha + self.beta + self.gamma\n        self.alpha = max(0.1, min(0.3, self.alpha / total_weight))\n        self.beta = max(0.6, min(0.8, self.beta / total_weight))\n        self.gamma = 1 - self.alpha - self.beta\n\n        return self.alpha, self.beta, self.gamma","metadata":{"_cell_guid":"a89bca72-9054-4ba9-8fe9-2b0c6572733e","_uuid":"fe7418a5-f00f-4fb1-8992-1bc42af2c5d3","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-10-04T21:33:19.650027Z","iopub.execute_input":"2024-10-04T21:33:19.650365Z","iopub.status.idle":"2024-10-04T21:33:19.666588Z","shell.execute_reply.started":"2024-10-04T21:33:19.650316Z","shell.execute_reply":"2024-10-04T21:33:19.665766Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"def reparameterize(mu, logvar, dropout_rate=0.5):\n    std = torch.exp(0.5 * logvar)\n    eps = torch.randn_like(std)\n    z = mu + eps * std\n    z = F.dropout(z, p=dropout_rate, training=True)  # Apply dropout\n    return z\n\ndef compute_loss(reconstructed_imgs_list, original_imgs, mu, logvar, predicted_labels, true_labels, clf_loss_fn, epoch, total_epochs, balancer):\n    recon_loss = sum(\n        F.mse_loss(recon, original_imgs, reduction=\"mean\")\n        for recon in reconstructed_imgs_list\n    ) / len(reconstructed_imgs_list)\n\n    kld_loss = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n    clf_loss = clf_loss_fn(predicted_labels, true_labels)\n\n    alpha, beta, gamma = balancer.update(recon_loss + clf_loss + kld_loss, recon_loss, clf_loss, kld_loss)\n\n    total_loss = alpha * recon_loss + beta * clf_loss + gamma * kld_loss\n    return total_loss, recon_loss.item(), clf_loss.item(), kld_loss.item(), alpha, beta, gamma","metadata":{"execution":{"iopub.status.busy":"2024-10-04T21:33:19.667512Z","iopub.execute_input":"2024-10-04T21:33:19.667782Z","iopub.status.idle":"2024-10-04T21:33:19.681715Z","shell.execute_reply.started":"2024-10-04T21:33:19.667752Z","shell.execute_reply":"2024-10-04T21:33:19.680890Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"def mixup_data(x, y, alpha=1.0, device=\"cuda\"):\n    if alpha > 0:\n        lam = np.random.beta(alpha, alpha)\n    else:\n        lam = 1\n\n    batch_size = x.size()[0]\n    index = torch.randperm(batch_size).to(device)\n\n    mixed_x = lam * x + (1 - lam) * x[index, :]\n    y_a, y_b = y, y[index]\n    return mixed_x, y_a, y_b, lam\n\n\ndef mixup_criterion(criterion, pred, y_a, y_b, lam):\n    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)","metadata":{"_cell_guid":"5963984d-caaf-4e6c-abff-b2ced9337abb","_uuid":"64e2706d-9120-4121-9358-b00c42985b97","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-10-04T21:33:19.682739Z","iopub.execute_input":"2024-10-04T21:33:19.683019Z","iopub.status.idle":"2024-10-04T21:33:19.691905Z","shell.execute_reply.started":"2024-10-04T21:33:19.682990Z","shell.execute_reply":"2024-10-04T21:33:19.691111Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"def train_model_progressive(\n    encoder,\n    decoders,\n    classifier,\n    domains,\n    dataloader,\n    val_loaders,\n    test_loaders,  # Thêm test_loaders vào parameter\n    optimizer,\n    scheduler,\n    num_epochs=100,\n    device=\"cuda\",\n    patience=10,\n):\n    print(\"Training model with progressive domain adaptation\")\n    print(f\"Number of epochs: {num_epochs}\")\n    print(f\"Patience: {patience}\")\n    print(f\"Domains: {domains}\")\n    print(f\"Device: {device}\")\n    print(f\"Number of training samples: {len(dataloader.dataset)}\")\n    print(f\"Number of validation samples: {len(val_loaders[domains[0]].dataset)}\")\n    print(\n        f\"Number of test samples: {len(test_loaders[domains[0]].dataset)}\"\n    )  # Thêm thông tin test samples\n\n    clf_loss_fn = LabelSmoothingLoss(smoothing=0.1)\n    domain_to_idx = {domain: idx for idx, domain in enumerate(domains)}\n\n    best_loss = float(\"inf\")\n    patience_counter = 0\n    balancer = DynamicWeightBalancer()\n\n    for epoch in range(num_epochs):\n        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n        encoder.train()\n        classifier.train()\n        \n        for decoder in decoders.values():\n            decoder.train()\n\n        running_loss = 0.0\n        running_recon_loss = 0.0\n        running_clf_loss = 0.0\n        running_kl_loss = 0.0\n\n        # Khởi tạo `total_samples` trước vòng lặp\n        total_samples = 0  \n\n        # Training loop on train dataset\n        for inputs, labels in tqdm(dataloader, desc=\"Training\"):\n            inputs, labels = inputs.to(device), labels.to(device)\n\n            inputs, labels_a, labels_b, lam = mixup_data(\n                inputs, labels, alpha=0.2, device=device\n            )\n\n            mu, logvar = encoder(inputs)\n            z = reparameterize(mu, logvar)\n\n            reconstructed_imgs_list = []\n            for domain in domains:\n                domain_label = torch.tensor(\n                    [domain_to_idx[domain]] * inputs.size(0), device=device\n                )\n                reconstructed_imgs = decoders[domain](z, domain_label)\n                reconstructed_imgs_list.append(reconstructed_imgs)\n\n            predicted_labels = classifier(z)\n\n            loss, recon_loss, clf_loss, kl_loss, alpha, beta, gamma = compute_loss(\n                reconstructed_imgs_list,\n                inputs,\n                mu,\n                logvar,\n                predicted_labels,\n                labels,\n                lambda pred, target: mixup_criterion(\n                    clf_loss_fn, pred, labels_a, labels_b, lam\n                ),\n                epoch,\n                num_epochs,\n                balancer,\n            )\n\n            # Trong vòng lặp huấn luyện, trước khi gọi optimizer.step()\n            torch.nn.utils.clip_grad_norm_(encoder.parameters(), max_norm=1.0)\n            torch.nn.utils.clip_grad_norm_(classifier.parameters(), max_norm=1.0)\n            for decoder in decoders.values():\n                torch.nn.utils.clip_grad_norm_(decoder.parameters(), max_norm=1.0)\n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            running_loss += loss.item() * inputs.size(0)  # Nhân với số lượng mẫu trong batch\n            running_recon_loss += recon_loss * inputs.size(0)\n            running_clf_loss += clf_loss * inputs.size(0)\n            running_kl_loss += kl_loss * inputs.size(0)\n            total_samples += inputs.size(0)\n\n            avg_loss = running_loss / total_samples  # Tính trung bình dựa trên tổng số mẫu\n            avg_recon_loss = running_recon_loss / total_samples\n            avg_clf_loss = running_clf_loss / total_samples\n            avg_kl_loss = running_kl_loss / total_samples\n\n        print(\n            f\"Epoch {epoch + 1}, Loss: {avg_loss:.4f}, Recon: {avg_recon_loss:.4f}, Clf: {avg_clf_loss:.4f}, KL: {avg_kl_loss:.4f}\"\n        )\n        print(f\"Weights - Alpha: {alpha:.4f}, Beta: {beta:.4f}, Gamma: {gamma:.4f}\")\n\n        # Fine-tuning on validation dataset\n        encoder.eval()\n        classifier.eval()\n        for domain in domains:\n            val_loader = val_loaders[domain]\n            val_running_loss = 0.0\n            for inputs, labels in tqdm(val_loader, desc=f\"Fine-tuning on {domain}\"):\n                inputs, labels = inputs.to(device), labels.to(device)\n\n                mu, logvar = encoder(inputs)\n                z = reparameterize(mu, logvar)\n\n                reconstructed_imgs = decoders[domain](\n                    z,\n                    torch.tensor(\n                        [domain_to_idx[domain]] * inputs.size(0), device=device\n                    ),\n                )\n                predicted_labels = classifier(z)\n\n                val_loss, recon_loss, clf_loss, kl_loss, _, _, _ = compute_loss(\n                    [reconstructed_imgs],\n                    inputs,\n                    mu,\n                    logvar,\n                    predicted_labels,\n                    labels,\n                    clf_loss_fn,\n                    epoch,\n                    num_epochs,\n                    balancer,\n                )\n\n                optimizer.zero_grad()\n                val_loss.backward()\n                optimizer.step()\n\n                val_running_loss += val_loss.item()\n\n            avg_val_loss = val_running_loss / len(val_loader)\n            print(f\"Validation Fine-tuning Loss on {domain}: {avg_val_loss:.4f}\")\n\n        # Evaluate on test dataset every 5 epochs\n        if (epoch + 1) % 5 == 0:\n            print(f\"--- Evaluating on Test Set at Epoch {epoch + 1} ---\")\n            for domain in domains:\n                test_loader = test_loaders[domain]\n                test_running_loss = 0.0\n                test_accuracy = 0.0\n                total_samples = 0\n                for inputs, labels in tqdm(test_loader, desc=f\"Evaluating on {domain}\"):\n                    inputs, labels = inputs.to(device), labels.to(device)\n\n                    with torch.no_grad():\n                        mu, logvar = encoder(inputs)\n                        z = reparameterize(mu, logvar)\n                        reconstructed_imgs = decoders[domain](\n                            z,\n                            torch.tensor(\n                                [domain_to_idx[domain]] * inputs.size(0), device=device\n                            ),\n                        )\n                        predicted_labels = classifier(z)\n\n                        test_loss, recon_loss, clf_loss, kl_loss, _, _, _ = (\n                            compute_loss(\n                                [reconstructed_imgs],\n                                inputs,\n                                mu,\n                                logvar,\n                                predicted_labels,\n                                labels,\n                                clf_loss_fn,\n                                epoch,\n                                num_epochs,\n                                balancer,\n                            )\n                        )\n\n                        test_running_loss += test_loss.item()\n                        _, preds = torch.max(predicted_labels, 1)\n                        test_accuracy += torch.sum(preds == labels).item()\n                        total_samples += labels.size(0)\n\n                avg_test_loss = test_running_loss / len(test_loader)\n                test_accuracy = test_accuracy / total_samples * 100\n\n                print(\n                    f\"Test Loss on {domain}: {avg_test_loss:.4f}, \"\n                    f\"Test Accuracy on {domain}: {test_accuracy:.2f}%\"\n                )\n\n        # Early stopping dựa trên validation loss\n        if avg_val_loss < best_loss:  # Kiểm tra validation loss thay vì training loss\n            best_loss = avg_val_loss  # Cập nhật best_loss dựa trên validation loss\n            patience_counter = 0\n        else:\n            patience_counter += 1\n            if patience_counter >= patience:\n                print(f\"Early stopping triggered after {epoch + 1} epochs\")\n                break","metadata":{"execution":{"iopub.status.busy":"2024-10-04T21:33:19.693917Z","iopub.execute_input":"2024-10-04T21:33:19.694213Z","iopub.status.idle":"2024-10-04T21:33:19.723168Z","shell.execute_reply.started":"2024-10-04T21:33:19.694171Z","shell.execute_reply":"2024-10-04T21:33:19.722178Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"def evaluate_model(encoder, classifier, decoder, dataloader, device, domain_label):\n    encoder.eval()\n    classifier.eval()\n    decoder.eval()\n    total_clf_loss = 0.0\n    total_recon_loss = 0.0\n    correct = 0\n    total = 0\n    clf_loss_fn = nn.CrossEntropyLoss()\n    \n    with torch.no_grad():\n        for inputs, labels in tqdm(dataloader, desc=\"Evaluating\"):\n            inputs, labels = inputs.to(device), labels.to(device)\n            batch_size = inputs.size(0)\n            mu, logvar = encoder(inputs)\n            z = reparameterize(mu, logvar)\n            outputs = classifier(z)\n            \n            # Chuyển domain_label thành tensor và lặp lại cho mỗi mẫu trong batch\n            domain_labels = torch.full((batch_size,), domain_label, device=device)\n            reconstructed_imgs = decoder(z, domain_labels)\n\n            # Classification accuracy\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n            # Losses\n            clf_loss = clf_loss_fn(outputs, labels)\n            recon_loss = F.mse_loss(reconstructed_imgs, inputs, reduction=\"sum\")\n            total_clf_loss += clf_loss.item()\n            total_recon_loss += recon_loss.item()\n\n    accuracy = correct / total\n    avg_clf_loss = total_clf_loss / len(dataloader.dataset)\n    avg_recon_loss = total_recon_loss / len(dataloader.dataset)\n\n    print(f\"Accuracy: {accuracy:.2f}\")\n    print(f\"Avg Clf Loss: {avg_clf_loss:.4f}\")\n    print(f\"Avg Recon Loss: {avg_recon_loss:.4f}\")\n    return accuracy, avg_clf_loss, avg_recon_loss","metadata":{"_cell_guid":"2a3716ee-a41f-40f9-be92-6e13201957fc","_uuid":"c9b6247e-a3a8-4139-97cf-47beb2962809","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-10-04T23:51:59.972777Z","iopub.execute_input":"2024-10-04T23:51:59.973171Z","iopub.status.idle":"2024-10-04T23:51:59.983764Z","shell.execute_reply.started":"2024-10-04T23:51:59.973134Z","shell.execute_reply":"2024-10-04T23:51:59.982863Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"# Main training and evaluation script\nDATA_PATH = \"/kaggle/input/pacs-dataset/kfold\"  # Update this path to your dataset location\nlatent_dim = 256\nnum_classes = 7  # Update this according to your PACS dataset\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# Domains in PACS dataset\ndomains = [\"art_painting\", \"cartoon\", \"photo\", \"sketch\"]\n\n# Initialize models\nencoder = Encoder(latent_dim).to(device)\ndecoders = {domain: Decoder(latent_dim, len(domains)).to(device) for domain in domains}\nclassifier = Classifier(latent_dim, num_classes).to(device)\n\n# Optimizer and Scheduler\nparams = list(encoder.parameters()) + list(classifier.parameters())\nfor decoder in decoders.values():\n    params += list(decoder.parameters())\n\noptimizer = optim.AdamW(params, lr=1e-4, weight_decay=1e-5)\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(\n   optimizer, mode=\"min\", factor=0.1, patience=5\n)\n\n# Create a single DataLoader for all domains\ntrain_loader, val_loader, test_loader = get_dataloader(DATA_PATH, domains)\n\n# Create a dictionary for validation loaders if needed\nval_loaders = {domain: val_loader for domain in domains}\ntest_loaders = {domain: test_loader for domain in domains}\n\n# Train model using the combined DataLoader\ntrain_model_progressive(\n  encoder,\n  decoders,\n  classifier,\n  domains,\n  train_loader,\n  val_loaders,\n  test_loaders,\n  optimizer,\n  scheduler,\n  num_epochs=100,\n  device=device,\n  patience=10,\n)","metadata":{"_cell_guid":"674a907d-466e-49d6-b8e9-fc6483ee92f3","_uuid":"9339af62-d3b0-4922-b5a6-52ddb95a57f5","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-10-04T21:33:19.739290Z","iopub.execute_input":"2024-10-04T21:33:19.739571Z","iopub.status.idle":"2024-10-04T23:49:30.492991Z","shell.execute_reply.started":"2024-10-04T21:33:19.739542Z","shell.execute_reply":"2024-10-04T23:49:30.491076Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"Using device: cuda\nTraining model with progressive domain adaptation\nNumber of epochs: 100\nPatience: 10\nDomains: ['art_painting', 'cartoon', 'photo', 'sketch']\nDevice: cuda\nNumber of training samples: 6993\nNumber of validation samples: 1499\nNumber of test samples: 1499\nEpoch 1/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 219/219 [02:05<00:00,  1.74it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1, Loss: 2.1184, Recon: 2.4993, Clf: 2.3186, KL: 0.0286\nWeights - Alpha: 0.1000, Beta: 0.8000, Gamma: 0.1000\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on art_painting: 100%|██████████| 47/47 [00:23<00:00,  2.04it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on art_painting: 1.8021\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on cartoon: 100%|██████████| 47/47 [00:15<00:00,  3.00it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on cartoon: 1.7791\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on photo: 100%|██████████| 47/47 [00:15<00:00,  3.00it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on photo: 1.7396\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on sketch: 100%|██████████| 47/47 [00:15<00:00,  2.95it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on sketch: 1.7205\nEpoch 2/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 219/219 [01:32<00:00,  2.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2, Loss: 1.7024, Recon: 2.0875, Clf: 1.8505, KL: 0.1326\nWeights - Alpha: 0.1000, Beta: 0.8000, Gamma: 0.1000\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on art_painting: 100%|██████████| 47/47 [00:15<00:00,  2.95it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on art_painting: 1.4914\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on cartoon: 100%|██████████| 47/47 [00:15<00:00,  3.00it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on cartoon: 1.4539\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on photo: 100%|██████████| 47/47 [00:14<00:00,  3.28it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on photo: 1.4381\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on sketch: 100%|██████████| 47/47 [00:15<00:00,  3.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on sketch: 1.4359\nEpoch 3/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 219/219 [01:29<00:00,  2.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3, Loss: 1.5378, Recon: 1.9711, Clf: 1.6360, KL: 0.3187\nWeights - Alpha: 0.1000, Beta: 0.8000, Gamma: 0.1000\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on art_painting: 100%|██████████| 47/47 [00:15<00:00,  2.99it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on art_painting: 1.3621\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on cartoon: 100%|██████████| 47/47 [00:14<00:00,  3.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on cartoon: 1.3374\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on photo: 100%|██████████| 47/47 [00:14<00:00,  3.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on photo: 1.3458\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on sketch: 100%|██████████| 47/47 [00:14<00:00,  3.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on sketch: 1.3187\nEpoch 4/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 219/219 [01:30<00:00,  2.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4, Loss: 1.4896, Recon: 1.9173, Clf: 1.5684, KL: 0.4317\nWeights - Alpha: 0.1000, Beta: 0.8000, Gamma: 0.1000\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on art_painting: 100%|██████████| 47/47 [00:15<00:00,  2.95it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on art_painting: 1.2824\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on cartoon: 100%|██████████| 47/47 [00:15<00:00,  3.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on cartoon: 1.2723\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on photo: 100%|██████████| 47/47 [00:14<00:00,  3.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on photo: 1.2815\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on sketch: 100%|██████████| 47/47 [00:15<00:00,  3.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on sketch: 1.2774\nEpoch 5/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 219/219 [01:31<00:00,  2.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5, Loss: 1.4728, Recon: 1.8790, Clf: 1.5439, KL: 0.4977\nWeights - Alpha: 0.1000, Beta: 0.8000, Gamma: 0.1000\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on art_painting: 100%|██████████| 47/47 [00:15<00:00,  3.00it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on art_painting: 1.2408\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on cartoon: 100%|██████████| 47/47 [00:15<00:00,  3.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on cartoon: 1.2258\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on photo: 100%|██████████| 47/47 [00:13<00:00,  3.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on photo: 1.2401\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on sketch: 100%|██████████| 47/47 [00:15<00:00,  3.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on sketch: 1.2492\n--- Evaluating on Test Set at Epoch 5 ---\n","output_type":"stream"},{"name":"stderr","text":"Evaluating on art_painting: 100%|██████████| 47/47 [00:23<00:00,  1.99it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test Loss on art_painting: 1.2167, Test Accuracy on art_painting: 65.04%\n","output_type":"stream"},{"name":"stderr","text":"Evaluating on cartoon: 100%|██████████| 47/47 [00:14<00:00,  3.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test Loss on cartoon: 1.2184, Test Accuracy on cartoon: 63.64%\n","output_type":"stream"},{"name":"stderr","text":"Evaluating on photo: 100%|██████████| 47/47 [00:14<00:00,  3.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test Loss on photo: 1.2416, Test Accuracy on photo: 65.04%\n","output_type":"stream"},{"name":"stderr","text":"Evaluating on sketch: 100%|██████████| 47/47 [00:14<00:00,  3.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test Loss on sketch: 1.2485, Test Accuracy on sketch: 65.04%\nEpoch 6/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 219/219 [01:30<00:00,  2.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6, Loss: 1.4545, Recon: 1.8449, Clf: 1.5206, KL: 0.5356\nWeights - Alpha: 0.1000, Beta: 0.8000, Gamma: 0.1000\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on art_painting: 100%|██████████| 47/47 [00:15<00:00,  3.02it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on art_painting: 1.2323\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on cartoon: 100%|██████████| 47/47 [00:14<00:00,  3.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on cartoon: 1.2100\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on photo: 100%|██████████| 47/47 [00:14<00:00,  3.26it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on photo: 1.2190\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on sketch: 100%|██████████| 47/47 [00:15<00:00,  3.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on sketch: 1.2094\nEpoch 7/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 219/219 [01:32<00:00,  2.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7, Loss: 1.4482, Recon: 1.8349, Clf: 1.5106, KL: 0.5623\nWeights - Alpha: 0.1000, Beta: 0.8000, Gamma: 0.1000\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on art_painting: 100%|██████████| 47/47 [00:15<00:00,  3.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on art_painting: 1.2177\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on cartoon: 100%|██████████| 47/47 [00:14<00:00,  3.28it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on cartoon: 1.1897\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on photo: 100%|██████████| 47/47 [00:14<00:00,  3.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on photo: 1.2137\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on sketch: 100%|██████████| 47/47 [00:14<00:00,  3.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on sketch: 1.2038\nEpoch 8/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 219/219 [01:30<00:00,  2.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8, Loss: 1.4393, Recon: 1.7794, Clf: 1.5049, KL: 0.5744\nWeights - Alpha: 0.1000, Beta: 0.8000, Gamma: 0.1000\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on art_painting: 100%|██████████| 47/47 [00:15<00:00,  3.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on art_painting: 1.1864\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on cartoon: 100%|██████████| 47/47 [00:14<00:00,  3.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on cartoon: 1.1664\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on photo: 100%|██████████| 47/47 [00:15<00:00,  3.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on photo: 1.1928\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on sketch: 100%|██████████| 47/47 [00:14<00:00,  3.26it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on sketch: 1.1757\nEpoch 9/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 219/219 [01:31<00:00,  2.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9, Loss: 1.4236, Recon: 1.7757, Clf: 1.4853, KL: 0.5773\nWeights - Alpha: 0.1000, Beta: 0.8000, Gamma: 0.1000\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on art_painting: 100%|██████████| 47/47 [00:15<00:00,  3.01it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on art_painting: 1.1854\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on cartoon: 100%|██████████| 47/47 [00:14<00:00,  3.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on cartoon: 1.1539\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on photo: 100%|██████████| 47/47 [00:15<00:00,  3.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on photo: 1.1897\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on sketch: 100%|██████████| 47/47 [00:14<00:00,  3.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on sketch: 1.1781\nEpoch 10/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 219/219 [01:30<00:00,  2.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10, Loss: 1.4463, Recon: 1.7154, Clf: 1.5213, KL: 0.5773\nWeights - Alpha: 0.1000, Beta: 0.8000, Gamma: 0.1000\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on art_painting: 100%|██████████| 47/47 [00:15<00:00,  3.04it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on art_painting: 1.1791\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on cartoon: 100%|██████████| 47/47 [00:15<00:00,  3.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on cartoon: 1.1613\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on photo: 100%|██████████| 47/47 [00:15<00:00,  3.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on photo: 1.1636\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on sketch: 100%|██████████| 47/47 [00:14<00:00,  3.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on sketch: 1.1716\n--- Evaluating on Test Set at Epoch 10 ---\n","output_type":"stream"},{"name":"stderr","text":"Evaluating on art_painting: 100%|██████████| 47/47 [00:14<00:00,  3.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test Loss on art_painting: 1.1773, Test Accuracy on art_painting: 68.71%\n","output_type":"stream"},{"name":"stderr","text":"Evaluating on cartoon: 100%|██████████| 47/47 [00:14<00:00,  3.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test Loss on cartoon: 1.1627, Test Accuracy on cartoon: 68.51%\n","output_type":"stream"},{"name":"stderr","text":"Evaluating on photo: 100%|██████████| 47/47 [00:14<00:00,  3.30it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test Loss on photo: 1.1990, Test Accuracy on photo: 67.31%\n","output_type":"stream"},{"name":"stderr","text":"Evaluating on sketch: 100%|██████████| 47/47 [00:13<00:00,  3.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test Loss on sketch: 1.1910, Test Accuracy on sketch: 66.78%\nEpoch 11/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 219/219 [01:32<00:00,  2.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 11, Loss: 1.4138, Recon: 1.7254, Clf: 1.4799, KL: 0.5742\nWeights - Alpha: 0.1000, Beta: 0.8000, Gamma: 0.1000\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on art_painting: 100%|██████████| 47/47 [00:14<00:00,  3.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on art_painting: 1.1736\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on cartoon: 100%|██████████| 47/47 [00:14<00:00,  3.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on cartoon: 1.1255\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on photo: 100%|██████████| 47/47 [00:14<00:00,  3.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on photo: 1.1728\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on sketch: 100%|██████████| 47/47 [00:14<00:00,  3.28it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on sketch: 1.1583\nEpoch 12/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 219/219 [01:31<00:00,  2.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 12, Loss: 1.4011, Recon: 1.7652, Clf: 1.4597, KL: 0.5681\nWeights - Alpha: 0.1000, Beta: 0.8000, Gamma: 0.1000\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on art_painting: 100%|██████████| 47/47 [00:15<00:00,  2.96it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on art_painting: 1.1508\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on cartoon: 100%|██████████| 47/47 [00:15<00:00,  3.02it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on cartoon: 1.1283\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on photo: 100%|██████████| 47/47 [00:15<00:00,  3.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on photo: 1.1498\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on sketch: 100%|██████████| 47/47 [00:14<00:00,  3.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on sketch: 1.1503\nEpoch 13/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 219/219 [01:31<00:00,  2.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 13, Loss: 1.4202, Recon: 1.6969, Clf: 1.4924, KL: 0.5662\nWeights - Alpha: 0.1000, Beta: 0.8000, Gamma: 0.1000\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on art_painting: 100%|██████████| 47/47 [00:15<00:00,  3.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on art_painting: 1.1274\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on cartoon: 100%|██████████| 47/47 [00:14<00:00,  3.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on cartoon: 1.1319\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on photo: 100%|██████████| 47/47 [00:14<00:00,  3.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on photo: 1.1512\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on sketch: 100%|██████████| 47/47 [00:15<00:00,  3.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on sketch: 1.1345\nEpoch 14/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 219/219 [01:29<00:00,  2.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 14, Loss: 1.4181, Recon: 1.7080, Clf: 1.4893, KL: 0.5588\nWeights - Alpha: 0.1000, Beta: 0.8000, Gamma: 0.1000\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on art_painting: 100%|██████████| 47/47 [00:14<00:00,  3.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on art_painting: 1.1276\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on cartoon: 100%|██████████| 47/47 [00:14<00:00,  3.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on cartoon: 1.1238\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on photo: 100%|██████████| 47/47 [00:13<00:00,  3.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on photo: 1.1314\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on sketch: 100%|██████████| 47/47 [00:14<00:00,  3.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on sketch: 1.1410\nEpoch 15/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 219/219 [01:32<00:00,  2.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 15, Loss: 1.3963, Recon: 1.6957, Clf: 1.4637, KL: 0.5571\nWeights - Alpha: 0.1000, Beta: 0.8000, Gamma: 0.1000\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on art_painting: 100%|██████████| 47/47 [00:15<00:00,  3.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on art_painting: 1.1269\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on cartoon: 100%|██████████| 47/47 [00:14<00:00,  3.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on cartoon: 1.1234\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on photo: 100%|██████████| 47/47 [00:14<00:00,  3.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on photo: 1.1141\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on sketch: 100%|██████████| 47/47 [00:14<00:00,  3.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on sketch: 1.1282\n--- Evaluating on Test Set at Epoch 15 ---\n","output_type":"stream"},{"name":"stderr","text":"Evaluating on art_painting: 100%|██████████| 47/47 [00:14<00:00,  3.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test Loss on art_painting: 1.1338, Test Accuracy on art_painting: 70.05%\n","output_type":"stream"},{"name":"stderr","text":"Evaluating on cartoon: 100%|██████████| 47/47 [00:13<00:00,  3.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test Loss on cartoon: 1.1240, Test Accuracy on cartoon: 71.11%\n","output_type":"stream"},{"name":"stderr","text":"Evaluating on photo: 100%|██████████| 47/47 [00:14<00:00,  3.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test Loss on photo: 1.1712, Test Accuracy on photo: 68.45%\n","output_type":"stream"},{"name":"stderr","text":"Evaluating on sketch: 100%|██████████| 47/47 [00:13<00:00,  3.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test Loss on sketch: 1.1410, Test Accuracy on sketch: 70.45%\nEpoch 16/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 219/219 [01:31<00:00,  2.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 16, Loss: 1.3751, Recon: 1.6901, Clf: 1.4392, KL: 0.5473\nWeights - Alpha: 0.1000, Beta: 0.8000, Gamma: 0.1000\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on art_painting: 100%|██████████| 47/47 [00:16<00:00,  2.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on art_painting: 1.1277\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on cartoon: 100%|██████████| 47/47 [00:14<00:00,  3.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on cartoon: 1.1191\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on photo: 100%|██████████| 47/47 [00:15<00:00,  3.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on photo: 1.1062\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on sketch: 100%|██████████| 47/47 [00:14<00:00,  3.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on sketch: 1.1196\nEpoch 17/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 219/219 [01:32<00:00,  2.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 17, Loss: 1.4126, Recon: 1.6430, Clf: 1.4935, KL: 0.5347\nWeights - Alpha: 0.1000, Beta: 0.8000, Gamma: 0.1000\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on art_painting: 100%|██████████| 47/47 [00:14<00:00,  3.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on art_painting: 1.1137\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on cartoon: 100%|██████████| 47/47 [00:14<00:00,  3.26it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on cartoon: 1.1110\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on photo: 100%|██████████| 47/47 [00:14<00:00,  3.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on photo: 1.1078\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on sketch: 100%|██████████| 47/47 [00:15<00:00,  3.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on sketch: 1.1215\nEpoch 18/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 219/219 [01:30<00:00,  2.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 18, Loss: 1.3854, Recon: 1.6631, Clf: 1.4565, KL: 0.5388\nWeights - Alpha: 0.1000, Beta: 0.8000, Gamma: 0.1000\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on art_painting: 100%|██████████| 47/47 [00:15<00:00,  3.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on art_painting: 1.1069\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on cartoon: 100%|██████████| 47/47 [00:14<00:00,  3.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on cartoon: 1.0924\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on photo: 100%|██████████| 47/47 [00:14<00:00,  3.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on photo: 1.1003\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on sketch: 100%|██████████| 47/47 [00:14<00:00,  3.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on sketch: 1.0950\nEpoch 19/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 219/219 [01:30<00:00,  2.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 19, Loss: 1.3953, Recon: 1.6312, Clf: 1.4741, KL: 0.5292\nWeights - Alpha: 0.1000, Beta: 0.8000, Gamma: 0.1000\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on art_painting: 100%|██████████| 47/47 [00:15<00:00,  3.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on art_painting: 1.1258\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on cartoon: 100%|██████████| 47/47 [00:13<00:00,  3.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on cartoon: 1.1067\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on photo: 100%|██████████| 47/47 [00:15<00:00,  3.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on photo: 1.1170\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on sketch: 100%|██████████| 47/47 [00:14<00:00,  3.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on sketch: 1.1098\nEpoch 20/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 219/219 [01:31<00:00,  2.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 20, Loss: 1.3911, Recon: 1.6115, Clf: 1.4717, KL: 0.5261\nWeights - Alpha: 0.1000, Beta: 0.8000, Gamma: 0.1000\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on art_painting: 100%|██████████| 47/47 [00:15<00:00,  3.03it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on art_painting: 1.1225\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on cartoon: 100%|██████████| 47/47 [00:14<00:00,  3.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on cartoon: 1.1030\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on photo: 100%|██████████| 47/47 [00:14<00:00,  3.28it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on photo: 1.1072\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on sketch: 100%|██████████| 47/47 [00:14<00:00,  3.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on sketch: 1.1009\n--- Evaluating on Test Set at Epoch 20 ---\n","output_type":"stream"},{"name":"stderr","text":"Evaluating on art_painting: 100%|██████████| 47/47 [00:14<00:00,  3.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test Loss on art_painting: 1.1279, Test Accuracy on art_painting: 70.91%\n","output_type":"stream"},{"name":"stderr","text":"Evaluating on cartoon: 100%|██████████| 47/47 [00:14<00:00,  3.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test Loss on cartoon: 1.1281, Test Accuracy on cartoon: 69.78%\n","output_type":"stream"},{"name":"stderr","text":"Evaluating on photo: 100%|██████████| 47/47 [00:14<00:00,  3.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test Loss on photo: 1.1509, Test Accuracy on photo: 68.58%\n","output_type":"stream"},{"name":"stderr","text":"Evaluating on sketch: 100%|██████████| 47/47 [00:14<00:00,  3.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test Loss on sketch: 1.1472, Test Accuracy on sketch: 69.91%\nEpoch 21/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 219/219 [01:31<00:00,  2.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 21, Loss: 1.4035, Recon: 1.5910, Clf: 1.4893, KL: 0.5293\nWeights - Alpha: 0.1000, Beta: 0.8000, Gamma: 0.1000\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on art_painting: 100%|██████████| 47/47 [00:14<00:00,  3.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on art_painting: 1.1236\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on cartoon: 100%|██████████| 47/47 [00:14<00:00,  3.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on cartoon: 1.1014\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on photo: 100%|██████████| 47/47 [00:15<00:00,  3.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on photo: 1.1042\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on sketch: 100%|██████████| 47/47 [00:15<00:00,  3.02it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on sketch: 1.1097\nEpoch 22/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 219/219 [01:29<00:00,  2.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 22, Loss: 1.3734, Recon: 1.5880, Clf: 1.4523, KL: 0.5273\nWeights - Alpha: 0.1000, Beta: 0.8000, Gamma: 0.1000\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on art_painting: 100%|██████████| 47/47 [00:15<00:00,  2.95it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on art_painting: 1.0942\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on cartoon: 100%|██████████| 47/47 [00:14<00:00,  3.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on cartoon: 1.0836\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on photo: 100%|██████████| 47/47 [00:15<00:00,  3.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on photo: 1.0981\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on sketch: 100%|██████████| 47/47 [00:14<00:00,  3.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on sketch: 1.0833\nEpoch 23/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 219/219 [01:32<00:00,  2.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 23, Loss: 1.4050, Recon: 1.5652, Clf: 1.4959, KL: 0.5174\nWeights - Alpha: 0.1000, Beta: 0.8000, Gamma: 0.1000\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on art_painting: 100%|██████████| 47/47 [00:15<00:00,  3.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on art_painting: 1.1152\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on cartoon: 100%|██████████| 47/47 [00:14<00:00,  3.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on cartoon: 1.1079\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on photo: 100%|██████████| 47/47 [00:14<00:00,  3.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on photo: 1.1223\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on sketch: 100%|██████████| 47/47 [00:14<00:00,  3.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on sketch: 1.1080\nEpoch 24/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 219/219 [01:31<00:00,  2.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 24, Loss: 1.3823, Recon: 1.5696, Clf: 1.4669, KL: 0.5180\nWeights - Alpha: 0.1000, Beta: 0.8000, Gamma: 0.1000\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on art_painting: 100%|██████████| 47/47 [00:15<00:00,  3.02it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on art_painting: 1.1149\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on cartoon: 100%|██████████| 47/47 [00:14<00:00,  3.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on cartoon: 1.0951\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on photo: 100%|██████████| 47/47 [00:15<00:00,  3.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on photo: 1.1084\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on sketch: 100%|██████████| 47/47 [00:15<00:00,  3.04it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on sketch: 1.1073\nEpoch 25/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 219/219 [01:31<00:00,  2.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 25, Loss: 1.3607, Recon: 1.5925, Clf: 1.4374, KL: 0.5152\nWeights - Alpha: 0.1000, Beta: 0.8000, Gamma: 0.1000\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on art_painting: 100%|██████████| 47/47 [00:14<00:00,  3.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on art_painting: 1.0960\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on cartoon: 100%|██████████| 47/47 [00:14<00:00,  3.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on cartoon: 1.0868\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on photo: 100%|██████████| 47/47 [00:14<00:00,  3.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on photo: 1.0896\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on sketch: 100%|██████████| 47/47 [00:14<00:00,  3.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on sketch: 1.0922\n--- Evaluating on Test Set at Epoch 25 ---\n","output_type":"stream"},{"name":"stderr","text":"Evaluating on art_painting: 100%|██████████| 47/47 [00:15<00:00,  3.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test Loss on art_painting: 1.0889, Test Accuracy on art_painting: 73.05%\n","output_type":"stream"},{"name":"stderr","text":"Evaluating on cartoon: 100%|██████████| 47/47 [00:14<00:00,  3.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test Loss on cartoon: 1.1165, Test Accuracy on cartoon: 70.65%\n","output_type":"stream"},{"name":"stderr","text":"Evaluating on photo: 100%|██████████| 47/47 [00:14<00:00,  3.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test Loss on photo: 1.1181, Test Accuracy on photo: 70.45%\n","output_type":"stream"},{"name":"stderr","text":"Evaluating on sketch: 100%|██████████| 47/47 [00:16<00:00,  2.91it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test Loss on sketch: 1.1230, Test Accuracy on sketch: 71.38%\nEpoch 26/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 219/219 [01:31<00:00,  2.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 26, Loss: 1.3824, Recon: 1.5618, Clf: 1.4691, KL: 0.5100\nWeights - Alpha: 0.1000, Beta: 0.8000, Gamma: 0.1000\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on art_painting: 100%|██████████| 47/47 [00:16<00:00,  2.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on art_painting: 1.0934\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on cartoon: 100%|██████████| 47/47 [00:14<00:00,  3.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on cartoon: 1.0749\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on photo: 100%|██████████| 47/47 [00:14<00:00,  3.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on photo: 1.0901\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on sketch: 100%|██████████| 47/47 [00:14<00:00,  3.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on sketch: 1.0812\nEpoch 27/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 219/219 [01:31<00:00,  2.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 27, Loss: 1.3695, Recon: 1.5776, Clf: 1.4515, KL: 0.5055\nWeights - Alpha: 0.1000, Beta: 0.8000, Gamma: 0.1000\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on art_painting: 100%|██████████| 47/47 [00:15<00:00,  3.00it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on art_painting: 1.0972\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on cartoon: 100%|██████████| 47/47 [00:14<00:00,  3.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on cartoon: 1.0780\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on photo: 100%|██████████| 47/47 [00:14<00:00,  3.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on photo: 1.0925\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on sketch: 100%|██████████| 47/47 [00:14<00:00,  3.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on sketch: 1.0764\nEpoch 28/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 219/219 [01:31<00:00,  2.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 28, Loss: 1.3962, Recon: 1.5153, Clf: 1.4925, KL: 0.5067\nWeights - Alpha: 0.1000, Beta: 0.8000, Gamma: 0.1000\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on art_painting: 100%|██████████| 47/47 [00:15<00:00,  3.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on art_painting: 1.0955\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on cartoon: 100%|██████████| 47/47 [00:14<00:00,  3.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on cartoon: 1.0809\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on photo: 100%|██████████| 47/47 [00:14<00:00,  3.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on photo: 1.0965\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on sketch: 100%|██████████| 47/47 [00:14<00:00,  3.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on sketch: 1.0764\nEpoch 29/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 219/219 [01:31<00:00,  2.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 29, Loss: 1.3680, Recon: 1.5689, Clf: 1.4514, KL: 0.4998\nWeights - Alpha: 0.1000, Beta: 0.8000, Gamma: 0.1000\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on art_painting: 100%|██████████| 47/47 [00:15<00:00,  3.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on art_painting: 1.0899\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on cartoon: 100%|██████████| 47/47 [00:14<00:00,  3.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on cartoon: 1.0822\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on photo: 100%|██████████| 47/47 [00:15<00:00,  3.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on photo: 1.0731\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on sketch: 100%|██████████| 47/47 [00:14<00:00,  3.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on sketch: 1.0893\nEpoch 30/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 219/219 [01:30<00:00,  2.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 30, Loss: 1.3781, Recon: 1.5322, Clf: 1.4689, KL: 0.4978\nWeights - Alpha: 0.1000, Beta: 0.8000, Gamma: 0.1000\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on art_painting: 100%|██████████| 47/47 [00:15<00:00,  2.97it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on art_painting: 1.0862\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on cartoon: 100%|██████████| 47/47 [00:13<00:00,  3.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on cartoon: 1.0837\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on photo: 100%|██████████| 47/47 [00:14<00:00,  3.26it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on photo: 1.0718\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on sketch: 100%|██████████| 47/47 [00:13<00:00,  3.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on sketch: 1.0664\n--- Evaluating on Test Set at Epoch 30 ---\n","output_type":"stream"},{"name":"stderr","text":"Evaluating on art_painting: 100%|██████████| 47/47 [00:14<00:00,  3.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test Loss on art_painting: 1.1043, Test Accuracy on art_painting: 71.91%\n","output_type":"stream"},{"name":"stderr","text":"Evaluating on cartoon: 100%|██████████| 47/47 [00:13<00:00,  3.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test Loss on cartoon: 1.0997, Test Accuracy on cartoon: 72.38%\n","output_type":"stream"},{"name":"stderr","text":"Evaluating on photo: 100%|██████████| 47/47 [00:13<00:00,  3.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test Loss on photo: 1.1104, Test Accuracy on photo: 72.25%\n","output_type":"stream"},{"name":"stderr","text":"Evaluating on sketch: 100%|██████████| 47/47 [00:15<00:00,  3.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test Loss on sketch: 1.1154, Test Accuracy on sketch: 70.45%\nEpoch 31/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 219/219 [01:29<00:00,  2.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 31, Loss: 1.3735, Recon: 1.5269, Clf: 1.4641, KL: 0.4947\nWeights - Alpha: 0.1000, Beta: 0.8000, Gamma: 0.1000\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on art_painting: 100%|██████████| 47/47 [00:14<00:00,  3.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on art_painting: 1.0873\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on cartoon: 100%|██████████| 47/47 [00:14<00:00,  3.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on cartoon: 1.0650\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on photo: 100%|██████████| 47/47 [00:14<00:00,  3.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on photo: 1.0803\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on sketch: 100%|██████████| 47/47 [00:14<00:00,  3.26it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on sketch: 1.0717\nEpoch 32/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 219/219 [01:30<00:00,  2.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 32, Loss: 1.3765, Recon: 1.5281, Clf: 1.4676, KL: 0.4967\nWeights - Alpha: 0.1000, Beta: 0.8000, Gamma: 0.1000\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on art_painting: 100%|██████████| 47/47 [00:15<00:00,  3.01it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on art_painting: 1.0969\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on cartoon: 100%|██████████| 47/47 [00:14<00:00,  3.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on cartoon: 1.0682\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on photo: 100%|██████████| 47/47 [00:14<00:00,  3.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on photo: 1.0804\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on sketch: 100%|██████████| 47/47 [00:14<00:00,  3.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on sketch: 1.0725\nEpoch 33/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 219/219 [01:32<00:00,  2.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 33, Loss: 1.3646, Recon: 1.5200, Clf: 1.4539, KL: 0.4952\nWeights - Alpha: 0.1000, Beta: 0.8000, Gamma: 0.1000\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on art_painting: 100%|██████████| 47/47 [00:14<00:00,  3.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on art_painting: 1.0641\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on cartoon: 100%|██████████| 47/47 [00:14<00:00,  3.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on cartoon: 1.0585\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on photo: 100%|██████████| 47/47 [00:14<00:00,  3.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on photo: 1.0679\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on sketch: 100%|██████████| 47/47 [00:14<00:00,  3.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on sketch: 1.0666\nEpoch 34/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 219/219 [01:29<00:00,  2.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 34, Loss: 1.3783, Recon: 1.5188, Clf: 1.4708, KL: 0.4976\nWeights - Alpha: 0.1000, Beta: 0.8000, Gamma: 0.1000\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on art_painting: 100%|██████████| 47/47 [00:15<00:00,  3.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on art_painting: 1.0828\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on cartoon: 100%|██████████| 47/47 [00:14<00:00,  3.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on cartoon: 1.0644\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on photo: 100%|██████████| 47/47 [00:14<00:00,  3.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on photo: 1.0816\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on sketch: 100%|██████████| 47/47 [00:14<00:00,  3.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on sketch: 1.0650\nEpoch 35/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 219/219 [01:31<00:00,  2.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 35, Loss: 1.3550, Recon: 1.5125, Clf: 1.4422, KL: 0.4999\nWeights - Alpha: 0.1000, Beta: 0.8000, Gamma: 0.1000\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on art_painting: 100%|██████████| 47/47 [00:14<00:00,  3.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on art_painting: 1.0760\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on cartoon: 100%|██████████| 47/47 [00:14<00:00,  3.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on cartoon: 1.0704\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on photo: 100%|██████████| 47/47 [00:14<00:00,  3.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on photo: 1.0783\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on sketch: 100%|██████████| 47/47 [00:14<00:00,  3.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on sketch: 1.0673\n--- Evaluating on Test Set at Epoch 35 ---\n","output_type":"stream"},{"name":"stderr","text":"Evaluating on art_painting: 100%|██████████| 47/47 [00:14<00:00,  3.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test Loss on art_painting: 1.0938, Test Accuracy on art_painting: 71.65%\n","output_type":"stream"},{"name":"stderr","text":"Evaluating on cartoon: 100%|██████████| 47/47 [00:13<00:00,  3.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test Loss on cartoon: 1.0984, Test Accuracy on cartoon: 71.78%\n","output_type":"stream"},{"name":"stderr","text":"Evaluating on photo: 100%|██████████| 47/47 [00:14<00:00,  3.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test Loss on photo: 1.1125, Test Accuracy on photo: 70.25%\n","output_type":"stream"},{"name":"stderr","text":"Evaluating on sketch: 100%|██████████| 47/47 [00:14<00:00,  3.26it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test Loss on sketch: 1.0949, Test Accuracy on sketch: 72.78%\nEpoch 36/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 219/219 [01:30<00:00,  2.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 36, Loss: 1.3643, Recon: 1.5276, Clf: 1.4529, KL: 0.4926\nWeights - Alpha: 0.1000, Beta: 0.8000, Gamma: 0.1000\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on art_painting: 100%|██████████| 47/47 [00:15<00:00,  3.04it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on art_painting: 1.0833\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on cartoon: 100%|██████████| 47/47 [00:14<00:00,  3.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on cartoon: 1.0705\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on photo: 100%|██████████| 47/47 [00:14<00:00,  3.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on photo: 1.0817\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on sketch: 100%|██████████| 47/47 [00:14<00:00,  3.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on sketch: 1.0677\nEpoch 37/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 219/219 [01:32<00:00,  2.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 37, Loss: 1.3717, Recon: 1.4691, Clf: 1.4704, KL: 0.4853\nWeights - Alpha: 0.1000, Beta: 0.8000, Gamma: 0.1000\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on art_painting: 100%|██████████| 47/47 [00:15<00:00,  3.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on art_painting: 1.0807\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on cartoon: 100%|██████████| 47/47 [00:15<00:00,  3.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on cartoon: 1.0757\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on photo: 100%|██████████| 47/47 [00:15<00:00,  3.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on photo: 1.0623\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on sketch: 100%|██████████| 47/47 [00:15<00:00,  3.01it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on sketch: 1.0393\nEpoch 38/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 219/219 [01:33<00:00,  2.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 38, Loss: 1.3947, Recon: 1.4692, Clf: 1.4991, KL: 0.4847\nWeights - Alpha: 0.1000, Beta: 0.8000, Gamma: 0.1000\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on art_painting: 100%|██████████| 47/47 [00:15<00:00,  2.96it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on art_painting: 1.0812\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on cartoon: 100%|██████████| 47/47 [00:15<00:00,  3.05it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on cartoon: 1.0674\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on photo: 100%|██████████| 47/47 [00:15<00:00,  3.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on photo: 1.0852\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on sketch: 100%|██████████| 47/47 [00:14<00:00,  3.30it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on sketch: 1.0667\nEpoch 39/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 219/219 [01:30<00:00,  2.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 39, Loss: 1.3711, Recon: 1.4659, Clf: 1.4698, KL: 0.4869\nWeights - Alpha: 0.1000, Beta: 0.8000, Gamma: 0.1000\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on art_painting: 100%|██████████| 47/47 [00:14<00:00,  3.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on art_painting: 1.0713\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on cartoon: 100%|██████████| 47/47 [00:13<00:00,  3.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on cartoon: 1.0581\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on photo: 100%|██████████| 47/47 [00:14<00:00,  3.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on photo: 1.0591\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on sketch: 100%|██████████| 47/47 [00:14<00:00,  3.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on sketch: 1.0592\nEpoch 40/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 219/219 [01:30<00:00,  2.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 40, Loss: 1.3642, Recon: 1.4830, Clf: 1.4587, KL: 0.4887\nWeights - Alpha: 0.1000, Beta: 0.8000, Gamma: 0.1000\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on art_painting: 100%|██████████| 47/47 [00:14<00:00,  3.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on art_painting: 1.0736\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on cartoon: 100%|██████████| 47/47 [00:14<00:00,  3.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on cartoon: 1.0533\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on photo: 100%|██████████| 47/47 [00:14<00:00,  3.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on photo: 1.0425\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on sketch: 100%|██████████| 47/47 [00:14<00:00,  3.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on sketch: 1.0655\n--- Evaluating on Test Set at Epoch 40 ---\n","output_type":"stream"},{"name":"stderr","text":"Evaluating on art_painting: 100%|██████████| 47/47 [00:14<00:00,  3.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test Loss on art_painting: 1.0928, Test Accuracy on art_painting: 71.65%\n","output_type":"stream"},{"name":"stderr","text":"Evaluating on cartoon: 100%|██████████| 47/47 [00:13<00:00,  3.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test Loss on cartoon: 1.0851, Test Accuracy on cartoon: 72.78%\n","output_type":"stream"},{"name":"stderr","text":"Evaluating on photo: 100%|██████████| 47/47 [00:13<00:00,  3.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test Loss on photo: 1.0845, Test Accuracy on photo: 72.85%\n","output_type":"stream"},{"name":"stderr","text":"Evaluating on sketch: 100%|██████████| 47/47 [00:13<00:00,  3.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test Loss on sketch: 1.0790, Test Accuracy on sketch: 74.05%\nEpoch 41/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 219/219 [01:31<00:00,  2.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 41, Loss: 1.3778, Recon: 1.4668, Clf: 1.4783, KL: 0.4842\nWeights - Alpha: 0.1000, Beta: 0.8000, Gamma: 0.1000\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on art_painting: 100%|██████████| 47/47 [00:15<00:00,  3.00it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on art_painting: 1.0856\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on cartoon: 100%|██████████| 47/47 [00:13<00:00,  3.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on cartoon: 1.0661\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on photo: 100%|██████████| 47/47 [00:14<00:00,  3.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on photo: 1.0556\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on sketch: 100%|██████████| 47/47 [00:14<00:00,  3.26it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on sketch: 1.0483\nEpoch 42/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 219/219 [01:31<00:00,  2.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 42, Loss: 1.3571, Recon: 1.5070, Clf: 1.4470, KL: 0.4877\nWeights - Alpha: 0.1000, Beta: 0.8000, Gamma: 0.1000\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on art_painting: 100%|██████████| 47/47 [00:15<00:00,  3.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on art_painting: 1.0716\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on cartoon: 100%|██████████| 47/47 [00:14<00:00,  3.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on cartoon: 1.0650\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on photo: 100%|██████████| 47/47 [00:14<00:00,  3.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on photo: 1.0691\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on sketch: 100%|██████████| 47/47 [00:14<00:00,  3.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on sketch: 1.0723\nEpoch 43/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 219/219 [01:32<00:00,  2.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 43, Loss: 1.3702, Recon: 1.4668, Clf: 1.4682, KL: 0.4900\nWeights - Alpha: 0.1000, Beta: 0.8000, Gamma: 0.1000\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on art_painting: 100%|██████████| 47/47 [00:15<00:00,  2.96it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on art_painting: 1.0625\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on cartoon: 100%|██████████| 47/47 [00:15<00:00,  3.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on cartoon: 1.0619\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on photo: 100%|██████████| 47/47 [00:14<00:00,  3.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on photo: 1.0489\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on sketch: 100%|██████████| 47/47 [00:15<00:00,  3.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on sketch: 1.0472\nEpoch 44/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 219/219 [01:31<00:00,  2.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 44, Loss: 1.3709, Recon: 1.4854, Clf: 1.4669, KL: 0.4884\nWeights - Alpha: 0.1000, Beta: 0.8000, Gamma: 0.1000\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on art_painting: 100%|██████████| 47/47 [00:15<00:00,  3.02it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on art_painting: 1.0685\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on cartoon: 100%|██████████| 47/47 [00:15<00:00,  3.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on cartoon: 1.0546\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on photo: 100%|██████████| 47/47 [00:14<00:00,  3.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on photo: 1.0497\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on sketch: 100%|██████████| 47/47 [00:14<00:00,  3.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on sketch: 1.0423\nEpoch 45/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 219/219 [01:30<00:00,  2.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 45, Loss: 1.3556, Recon: 1.4910, Clf: 1.4469, KL: 0.4903\nWeights - Alpha: 0.1000, Beta: 0.8000, Gamma: 0.1000\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on art_painting: 100%|██████████| 47/47 [00:16<00:00,  2.93it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on art_painting: 1.0617\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on cartoon: 100%|██████████| 47/47 [00:14<00:00,  3.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on cartoon: 1.0604\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on photo: 100%|██████████| 47/47 [00:14<00:00,  3.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on photo: 1.0364\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on sketch: 100%|██████████| 47/47 [00:14<00:00,  3.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on sketch: 1.0431\n--- Evaluating on Test Set at Epoch 45 ---\n","output_type":"stream"},{"name":"stderr","text":"Evaluating on art_painting: 100%|██████████| 47/47 [00:14<00:00,  3.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test Loss on art_painting: 1.0961, Test Accuracy on art_painting: 71.45%\n","output_type":"stream"},{"name":"stderr","text":"Evaluating on cartoon: 100%|██████████| 47/47 [00:13<00:00,  3.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test Loss on cartoon: 1.0824, Test Accuracy on cartoon: 72.72%\n","output_type":"stream"},{"name":"stderr","text":"Evaluating on photo: 100%|██████████| 47/47 [00:13<00:00,  3.37it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test Loss on photo: 1.1006, Test Accuracy on photo: 72.78%\n","output_type":"stream"},{"name":"stderr","text":"Evaluating on sketch: 100%|██████████| 47/47 [00:14<00:00,  3.30it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test Loss on sketch: 1.0915, Test Accuracy on sketch: 72.65%\nEpoch 46/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 219/219 [01:31<00:00,  2.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 46, Loss: 1.3636, Recon: 1.4861, Clf: 1.4581, KL: 0.4855\nWeights - Alpha: 0.1000, Beta: 0.8000, Gamma: 0.1000\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on art_painting: 100%|██████████| 47/47 [00:14<00:00,  3.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on art_painting: 1.0563\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on cartoon: 100%|██████████| 47/47 [00:14<00:00,  3.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on cartoon: 1.0583\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on photo: 100%|██████████| 47/47 [00:15<00:00,  3.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on photo: 1.0384\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on sketch: 100%|██████████| 47/47 [00:15<00:00,  3.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on sketch: 1.0409\nEpoch 47/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 219/219 [01:30<00:00,  2.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 47, Loss: 1.3568, Recon: 1.4662, Clf: 1.4513, KL: 0.4909\nWeights - Alpha: 0.1000, Beta: 0.8000, Gamma: 0.1000\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on art_painting: 100%|██████████| 47/47 [00:15<00:00,  3.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on art_painting: 1.0642\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on cartoon: 100%|██████████| 47/47 [00:14<00:00,  3.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on cartoon: 1.0405\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on photo: 100%|██████████| 47/47 [00:14<00:00,  3.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on photo: 1.0349\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on sketch: 100%|██████████| 47/47 [00:14<00:00,  3.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on sketch: 1.0355\nEpoch 48/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 219/219 [01:31<00:00,  2.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 48, Loss: 1.3526, Recon: 1.4681, Clf: 1.4466, KL: 0.4858\nWeights - Alpha: 0.1000, Beta: 0.8000, Gamma: 0.1000\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on art_painting: 100%|██████████| 47/47 [00:16<00:00,  2.92it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on art_painting: 1.0487\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on cartoon: 100%|██████████| 47/47 [00:14<00:00,  3.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on cartoon: 1.0564\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on photo: 100%|██████████| 47/47 [00:14<00:00,  3.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on photo: 1.0489\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on sketch: 100%|██████████| 47/47 [00:14<00:00,  3.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on sketch: 1.0415\nEpoch 49/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 219/219 [01:32<00:00,  2.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 49, Loss: 1.3698, Recon: 1.4463, Clf: 1.4700, KL: 0.4920\nWeights - Alpha: 0.1000, Beta: 0.8000, Gamma: 0.1000\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on art_painting: 100%|██████████| 47/47 [00:14<00:00,  3.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on art_painting: 1.0822\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on cartoon: 100%|██████████| 47/47 [00:14<00:00,  3.26it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on cartoon: 1.0660\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on photo: 100%|██████████| 47/47 [00:14<00:00,  3.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on photo: 1.0630\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on sketch: 100%|██████████| 47/47 [00:14<00:00,  3.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on sketch: 1.0601\nEpoch 50/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 219/219 [01:31<00:00,  2.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 50, Loss: 1.3488, Recon: 1.4562, Clf: 1.4430, KL: 0.4881\nWeights - Alpha: 0.1000, Beta: 0.8000, Gamma: 0.1000\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on art_painting: 100%|██████████| 47/47 [00:15<00:00,  2.94it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on art_painting: 1.0473\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on cartoon: 100%|██████████| 47/47 [00:15<00:00,  3.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on cartoon: 1.0462\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on photo: 100%|██████████| 47/47 [00:14<00:00,  3.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on photo: 1.0352\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning on sketch: 100%|██████████| 47/47 [00:15<00:00,  3.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Fine-tuning Loss on sketch: 1.0396\n--- Evaluating on Test Set at Epoch 50 ---\n","output_type":"stream"},{"name":"stderr","text":"Evaluating on art_painting: 100%|██████████| 47/47 [00:15<00:00,  3.01it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test Loss on art_painting: 1.0632, Test Accuracy on art_painting: 74.52%\n","output_type":"stream"},{"name":"stderr","text":"Evaluating on cartoon: 100%|██████████| 47/47 [00:13<00:00,  3.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test Loss on cartoon: 1.0841, Test Accuracy on cartoon: 73.32%\n","output_type":"stream"},{"name":"stderr","text":"Evaluating on photo: 100%|██████████| 47/47 [00:14<00:00,  3.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test Loss on photo: 1.0705, Test Accuracy on photo: 73.45%\n","output_type":"stream"},{"name":"stderr","text":"Evaluating on sketch: 100%|██████████| 47/47 [00:14<00:00,  3.30it/s]\n","output_type":"stream"},{"name":"stdout","text":"Test Loss on sketch: 1.0820, Test Accuracy on sketch: 71.85%\nEpoch 51/100\n","output_type":"stream"},{"name":"stderr","text":"Training:   3%|▎         | 6/219 [00:02<01:41,  2.09it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[44], line 34\u001b[0m\n\u001b[1;32m     31\u001b[0m test_loaders \u001b[38;5;241m=\u001b[39m {domain: test_loader \u001b[38;5;28;01mfor\u001b[39;00m domain \u001b[38;5;129;01min\u001b[39;00m domains}\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Train model using the combined DataLoader\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m \u001b[43mtrain_model_progressive\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m  \u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m  \u001b[49m\u001b[43mdecoders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m  \u001b[49m\u001b[43mclassifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m  \u001b[49m\u001b[43mdomains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m  \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m  \u001b[49m\u001b[43mval_loaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m  \u001b[49m\u001b[43mtest_loaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Thêm test_loader vào parameter\u001b[39;49;00m\n\u001b[1;32m     42\u001b[0m \u001b[43m  \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m  \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m  \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m  \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m  \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[42], line 50\u001b[0m, in \u001b[0;36mtrain_model_progressive\u001b[0;34m(encoder, decoders, classifier, domains, dataloader, val_loaders, test_loaders, optimizer, scheduler, num_epochs, device, patience)\u001b[0m\n\u001b[1;32m     47\u001b[0m total_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m  \n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# Training loop on train dataset\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m tqdm(dataloader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     51\u001b[0m     inputs, labels \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     53\u001b[0m     inputs, labels_a, labels_b, lam \u001b[38;5;241m=\u001b[39m mixup_data(\n\u001b[1;32m     54\u001b[0m         inputs, labels, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice\n\u001b[1;32m     55\u001b[0m     )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n","Cell \u001b[0;32mIn[36], line 37\u001b[0m, in \u001b[0;36mPACSDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     34\u001b[0m label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels[idx]\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n\u001b[0;32m---> 37\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m image, label\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/transforms/transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/transforms/transforms.py:354\u001b[0m, in \u001b[0;36mResize.forward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m    347\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;124;03m        img (PIL Image or Tensor): Image to be scaled.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;124;03m        PIL Image or Tensor: Rescaled image.\u001b[39;00m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 354\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mantialias\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py:477\u001b[0m, in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation, max_size, antialias)\u001b[0m\n\u001b[1;32m    475\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnti-alias option is always applied for PIL Image input. Argument antialias is ignored.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    476\u001b[0m     pil_interpolation \u001b[38;5;241m=\u001b[39m pil_modes_mapping[interpolation]\n\u001b[0;32m--> 477\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF_pil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpil_interpolation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F_t\u001b[38;5;241m.\u001b[39mresize(img, size\u001b[38;5;241m=\u001b[39moutput_size, interpolation\u001b[38;5;241m=\u001b[39minterpolation\u001b[38;5;241m.\u001b[39mvalue, antialias\u001b[38;5;241m=\u001b[39mantialias)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/transforms/_functional_pil.py:250\u001b[0m, in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(size, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(size) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m):\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot inappropriate size arg: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 250\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/PIL/Image.py:2328\u001b[0m, in \u001b[0;36mImage.resize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   2316\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2317\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduce(factor, box\u001b[38;5;241m=\u001b[39mreduce_box)\n\u001b[1;32m   2318\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduce)\n\u001b[1;32m   2319\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m Image\u001b[38;5;241m.\u001b[39mreduce(\u001b[38;5;28mself\u001b[39m, factor, box\u001b[38;5;241m=\u001b[39mreduce_box)\n\u001b[1;32m   2320\u001b[0m         )\n\u001b[1;32m   2321\u001b[0m         box \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2322\u001b[0m             (box[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_x,\n\u001b[1;32m   2323\u001b[0m             (box[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_y,\n\u001b[1;32m   2324\u001b[0m             (box[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_x,\n\u001b[1;32m   2325\u001b[0m             (box[\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_y,\n\u001b[1;32m   2326\u001b[0m         )\n\u001b[0;32m-> 2328\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbox\u001b[49m\u001b[43m)\u001b[49m)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"# Final evaluation on the test set for each domain\nfor domain in domains:\n    print(f\"Evaluating on test set for domain: {domain}\")\n    evaluate_model(\n        encoder,\n        classifier,\n        decoders[domain],\n        test_loaders[domain],\n        device,\n        domains.index(domain),\n    )","metadata":{"_cell_guid":"f262034e-f894-4254-bf2a-468a053576ba","_uuid":"c9bc6a5c-94e6-4092-89a6-05ce1938018a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-10-04T23:52:08.999646Z","iopub.execute_input":"2024-10-04T23:52:09.000032Z","iopub.status.idle":"2024-10-04T23:53:06.334064Z","shell.execute_reply.started":"2024-10-04T23:52:08.999995Z","shell.execute_reply":"2024-10-04T23:53:06.333121Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"Evaluating on test set for domain: art_painting\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|██████████| 47/47 [00:14<00:00,  3.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.72\nAvg Clf Loss: 0.0276\nAvg Recon Loss: 252235.8319\nEvaluating on test set for domain: cartoon\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|██████████| 47/47 [00:14<00:00,  3.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.74\nAvg Clf Loss: 0.0269\nAvg Recon Loss: 248880.3929\nEvaluating on test set for domain: photo\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|██████████| 47/47 [00:14<00:00,  3.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.72\nAvg Clf Loss: 0.0277\nAvg Recon Loss: 254421.8319\nEvaluating on test set for domain: sketch\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|██████████| 47/47 [00:14<00:00,  3.33it/s]","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.74\nAvg Clf Loss: 0.0268\nAvg Recon Loss: 254533.3746\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
{"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9545143,"sourceType":"datasetVersion","datasetId":5815134}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import datasets, transforms, models\nfrom tqdm import tqdm\nfrom PIL import Image\nimport os\nimport torch.nn.functional as F","metadata":{"execution":{"iopub.status.busy":"2024-10-04T13:01:46.359208Z","iopub.execute_input":"2024-10-04T13:01:46.359742Z","iopub.status.idle":"2024-10-04T13:01:46.366002Z","shell.execute_reply.started":"2024-10-04T13:01:46.359672Z","shell.execute_reply":"2024-10-04T13:01:46.364928Z"},"trusted":true},"execution_count":96,"outputs":[]},{"cell_type":"code","source":"import random\nimport numpy as np\n\ndef set_random_seeds(seed_value=42):\n    torch.manual_seed(seed_value)\n    torch.cuda.manual_seed(seed_value)\n    torch.cuda.manual_seed_all(seed_value)  # if you are using multi-GPU.\n    np.random.seed(seed_value)  # Numpy module.\n    random.seed(seed_value)  # Python random module.\n    torch.backends.cudnn.benchmark = False\n    torch.backends.cudnn.deterministic = True\n\nset_random_seeds()","metadata":{"execution":{"iopub.status.busy":"2024-10-04T13:01:46.367664Z","iopub.execute_input":"2024-10-04T13:01:46.368001Z","iopub.status.idle":"2024-10-04T13:01:46.380121Z","shell.execute_reply.started":"2024-10-04T13:01:46.367965Z","shell.execute_reply":"2024-10-04T13:01:46.379164Z"},"trusted":true},"execution_count":97,"outputs":[]},{"cell_type":"code","source":"class PACSDataset(Dataset):\n    def __init__(self, root_dir, domain, transform=None):\n        self.root_dir = root_dir\n        self.domain = domain\n        self.transform = transform\n        self.images, self.labels = self._load_images_labels()\n\n    def _load_images_labels(self):\n        image_paths = []\n        labels = []\n        domain_dir = os.path.join(self.root_dir, self.domain)\n        classes = sorted(\n            [\n                d\n                for d in os.listdir(domain_dir)\n                if os.path.isdir(os.path.join(domain_dir, d))\n            ]\n        )\n\n        for label, class_name in enumerate(classes):\n            class_dir = os.path.join(domain_dir, class_name)\n            for image_name in os.listdir(class_dir):\n                if image_name.endswith((\".png\", \".jpg\", \".jpeg\")):\n                    image_paths.append(os.path.join(class_dir, image_name))\n                    labels.append(label)\n\n        return image_paths, labels\n\n    def __len__(self):\n        return len(self.images)  # Return the number of images\n\n    def __getitem__(self, idx):\n        image_path = self.images[idx]\n        image = Image.open(image_path).convert(\"RGB\")\n        label = self.labels[idx]\n\n        if self.transform:\n            image = self.transform(image)\n\n        return image, label\n\n\ndef get_transform():\n    return transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomRotation(10),\n        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n        transforms.RandomErasing(p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3), value=0),\n    ])\n\n\ndef get_combined_dataloader(root_dir, domains, batch_size=32):\n    datasets = [\n        PACSDataset(root_dir, domain, transform=get_transform()) for domain in domains\n    ]\n    combined_dataset = torch.utils.data.ConcatDataset(datasets)\n    return DataLoader(combined_dataset, batch_size=batch_size, shuffle=True)\n\n\ndef get_dataloader(root_dir, domain, batch_size=32):\n    dataset = PACSDataset(root_dir, domain, transform=get_transform())\n    return DataLoader(dataset, batch_size=batch_size, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-10-04T13:01:46.381298Z","iopub.execute_input":"2024-10-04T13:01:46.382141Z","iopub.status.idle":"2024-10-04T13:01:46.397244Z","shell.execute_reply.started":"2024-10-04T13:01:46.382096Z","shell.execute_reply":"2024-10-04T13:01:46.396444Z"},"trusted":true},"execution_count":98,"outputs":[]},{"cell_type":"code","source":"# Define Encoder, Decoder, Classifier\nclass Encoder(nn.Module):\n    def __init__(self, latent_dim):\n        super(Encoder, self).__init__()\n\n        # Sử dụng EfficientNet-B1\n        self.efficientnet = models.efficientnet_b1(pretrained=True)\n\n        # Freeze EfficientNet layers\n        for param in self.efficientnet.parameters():\n            param.requires_grad = False\n\n        # Lấy số features từ lớp cuối cùng của EfficientNet-B1\n        in_features = self.efficientnet.classifier[1].in_features\n\n        # Attention mechanism\n        self.attention = nn.Sequential(\n            nn.Linear(in_features, in_features // 16),\n            nn.ReLU(),\n            nn.Linear(in_features // 16, in_features),\n            nn.Sigmoid(),\n        )\n\n        # Mean (mu) and log-variance (logvar) layers\n        self.fc_mu = nn.Linear(in_features, latent_dim)\n        self.fc_logvar = nn.Linear(in_features, latent_dim)\n\n    def forward(self, x):\n        # Pass input through EfficientNet feature extractor\n        features = self.efficientnet.features(x)\n        x = self.efficientnet.avgpool(features)\n        x = torch.flatten(x, 1)\n\n        # Apply attention\n        attention_weights = self.attention(x)\n        x = x * attention_weights\n\n        # Compute mu and logvar\n        mu = self.fc_mu(x)\n        logvar = self.fc_logvar(x)\n        return mu, logvar\n\n\nclass ResidualBlock(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(ResidualBlock, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n\n        self.shortcut = nn.Sequential()\n        if in_channels != out_channels:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_channels, out_channels, kernel_size=1),\n                nn.BatchNorm2d(out_channels),\n            )\n\n    def forward(self, x):\n        residual = x\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n        out += self.shortcut(residual)\n        out = F.relu(out)\n        return out\n\n\nclass Decoder(nn.Module):\n    def __init__(self, latent_dim, num_domains):\n        super(Decoder, self).__init__()\n\n        self.domain_embedding = nn.Embedding(num_domains, latent_dim)\n\n        self.fc = nn.Linear(latent_dim, 512 * 7 * 7)\n\n        self.decoder = nn.Sequential(\n            ResidualBlock(512, 256),\n            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(),\n            ResidualBlock(128, 128),\n            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            ResidualBlock(64, 64),\n            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),\n            nn.BatchNorm2d(32),\n            nn.ReLU(),\n            nn.ConvTranspose2d(32, 16, kernel_size=4, stride=2, padding=1),\n            nn.BatchNorm2d(16),\n            nn.ReLU(),\n            nn.ConvTranspose2d(16, 3, kernel_size=4, stride=2, padding=1),\n            nn.Tanh()  # Thêm Tanh để đảm bảo đầu ra trong khoảng [-1, 1]\n        )\n\n        # Attention mechanism\n        self.attention = nn.Sequential(nn.Conv2d(3, 1, kernel_size=1), nn.Sigmoid())\n\n    def forward(self, z, domain_label):\n        domain_embed = self.domain_embedding(domain_label)\n        z = z + domain_embed\n\n        x = self.fc(z)\n        x = x.view(-1, 512, 7, 7)\n        x = self.decoder(x)\n\n        # Apply attention\n        attention_map = self.attention(x)\n        x = x * attention_map\n\n        return x\n\n\nclass Classifier(nn.Module):\n    def __init__(self, latent_dim, num_classes):\n        super(Classifier, self).__init__()\n        self.fc = nn.Linear(latent_dim, num_classes)\n        self.dropout = nn.Dropout(0.5)\n\n    def forward(self, z):\n        z = self.dropout(z)\n        return self.fc(z)","metadata":{"execution":{"iopub.status.busy":"2024-10-04T13:01:46.398910Z","iopub.execute_input":"2024-10-04T13:01:46.399468Z","iopub.status.idle":"2024-10-04T13:01:46.422103Z","shell.execute_reply.started":"2024-10-04T13:01:46.399396Z","shell.execute_reply":"2024-10-04T13:01:46.421369Z"},"trusted":true},"execution_count":99,"outputs":[]},{"cell_type":"code","source":"def reparameterize(mu, logvar):\n    std = torch.exp(0.5 * logvar)\n    eps = torch.randn_like(std)\n    return mu + eps * std\n\n\nclass LabelSmoothingLoss(_WeightedLoss):\n    def __init__(self, weight=None, reduction=\"mean\", smoothing=0.0):\n        super().__init__(weight=weight, reduction=reduction)\n        self.smoothing = smoothing\n        self.weight = weight\n        self.reduction = reduction\n\n    def k_one_hot(self, targets: torch.Tensor, n_classes: int, smoothing=0.0):\n        with torch.no_grad():\n            targets = (\n                torch.empty(size=(targets.size(0), n_classes), device=targets.device)\n                .fill_(smoothing / (n_classes - 1))\n                .scatter_(1, targets.data.unsqueeze(1), 1.0 - smoothing)\n            )\n        return targets\n\n    def reduce_loss(self, loss):\n        return (\n            loss.mean()\n            if self.reduction == \"mean\"\n            else loss.sum() if self.reduction == \"sum\" else loss\n        )\n\n    def forward(self, inputs, targets):\n        assert 0 <= self.smoothing < 1\n\n        targets = self.k_one_hot(targets, inputs.size(-1), self.smoothing)\n        log_preds = F.log_softmax(inputs, -1)\n\n        if self.weight is not None:\n            log_preds = log_preds * self.weight.unsqueeze(0)\n\n        return self.reduce_loss(-(targets * log_preds).sum(dim=-1))\n\n\ndef compute_loss(\n    reconstructed_imgs_list,\n    original_imgs,\n    mu,\n    logvar,\n    predicted_labels,\n    true_labels,\n    clf_loss_fn,\n    epoch,\n    total_epochs,\n    alpha=1.0,\n    beta=1.0,\n    gamma=1.0,\n):\n    recon_loss = sum(\n        F.mse_loss(recon, original_imgs, reduction=\"sum\")\n        for recon in reconstructed_imgs_list\n    )\n\n    # KL Divergence annealing\n    annealing_factor = min(1.0, epoch / (total_epochs * 0.2))\n    kld_loss = (\n        -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp()) * annealing_factor\n    )\n\n    clf_loss = clf_loss_fn(predicted_labels, true_labels)\n\n    total_loss = alpha * recon_loss + beta * clf_loss + gamma * kld_loss\n    return total_loss, recon_loss.item(), clf_loss.item(), kld_loss.item()","metadata":{"execution":{"iopub.status.busy":"2024-10-04T13:01:46.508396Z","iopub.execute_input":"2024-10-04T13:01:46.508758Z","iopub.status.idle":"2024-10-04T13:01:46.522704Z","shell.execute_reply.started":"2024-10-04T13:01:46.508722Z","shell.execute_reply":"2024-10-04T13:01:46.521730Z"},"trusted":true},"execution_count":100,"outputs":[]},{"cell_type":"code","source":"def mixup_data(x, y, alpha=1.0, device=\"cuda\"):\n    if alpha > 0:\n        lam = np.random.beta(alpha, alpha)\n    else:\n        lam = 1\n\n    batch_size = x.size()[0]\n    index = torch.randperm(batch_size).to(device)\n\n    mixed_x = lam * x + (1 - lam) * x[index, :]\n    y_a, y_b = y, y[index]\n    return mixed_x, y_a, y_b, lam\n\n\ndef mixup_criterion(criterion, pred, y_a, y_b, lam):\n    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n\n\ndef train_model_progressive(\n    encoder,\n    decoders,\n    classifier,\n    domains,\n    dataloader,\n    optimizer,\n    scheduler,\n    num_epochs=100,\n    device=\"cuda\",\n    patience=10,\n):\n    clf_loss_fn = LabelSmoothingLoss(smoothing=0.1)\n    domain_to_idx = {domain: idx for idx, domain in enumerate(domains)}\n\n    best_loss = float(\"inf\")\n    patience_counter = 0\n\n    for epoch in range(num_epochs):\n        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n        encoder.train()\n        classifier.train()\n        for decoder in decoders.values():\n            decoder.train()\n\n        running_loss = 0.0\n        for inputs, labels in tqdm(dataloader, desc=\"Training\"):\n            inputs, labels = inputs.to(device), labels.to(device)\n\n            # Apply mixup\n            inputs, labels_a, labels_b, lam = mixup_data(\n                inputs, labels, alpha=0.2, device=device\n            )\n\n            mu, logvar = encoder(inputs)\n            z = reparameterize(mu, logvar)\n\n            reconstructed_imgs_list = []\n            for domain in domains:\n                domain_label = torch.tensor(\n                    [domain_to_idx[domain]] * inputs.size(0), device=device\n                )\n                reconstructed_imgs = decoders[domain](z, domain_label)\n                reconstructed_imgs_list.append(reconstructed_imgs)\n\n            predicted_labels = classifier(z)\n\n            loss, recon_loss, clf_loss, kld_loss = compute_loss(\n                reconstructed_imgs_list,\n                inputs,\n                mu,\n                logvar,\n                predicted_labels,\n                labels,\n                lambda pred, target: mixup_criterion(\n                    clf_loss_fn, pred, labels_a, labels_b, lam\n                ),\n                epoch,\n                num_epochs,\n            )\n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            running_loss += loss.item()\n\n        avg_loss = running_loss / len(dataloader)\n        print(f\"Epoch {epoch + 1}, Loss: {avg_loss:.4f}\")\n\n        scheduler.step(avg_loss)\n\n        if avg_loss < best_loss:\n            best_loss = avg_loss\n            patience_counter = 0\n        else:\n            patience_counter += 1\n            if patience_counter >= patience:\n                print(f\"Early stopping triggered after {epoch + 1} epochs\")\n                break","metadata":{"execution":{"iopub.status.busy":"2024-10-04T13:01:46.524394Z","iopub.execute_input":"2024-10-04T13:01:46.524781Z","iopub.status.idle":"2024-10-04T13:01:46.541319Z","shell.execute_reply.started":"2024-10-04T13:01:46.524742Z","shell.execute_reply":"2024-10-04T13:01:46.540533Z"},"trusted":true},"execution_count":101,"outputs":[]},{"cell_type":"code","source":"def evaluate_model(encoder, classifier, decoder, dataloader, device, domain_label):\n    encoder.eval()\n    classifier.eval()\n    decoder.eval()\n    total_clf_loss = 0.0\n    total_recon_loss = 0.0\n    correct = 0\n    total = 0\n    clf_loss_fn = nn.CrossEntropyLoss()\n    \n    with torch.no_grad():\n        for inputs, labels in tqdm(dataloader, desc=\"Evaluating\"):\n            inputs, labels = inputs.to(device), labels.to(device)\n            batch_size = inputs.size(0)\n            mu, logvar = encoder(inputs)\n            z = reparameterize(mu, logvar)\n            outputs = classifier(z)\n            \n            # Chuyển domain_label thành tensor và lặp lại cho mỗi mẫu trong batch\n            domain_labels = torch.full((batch_size,), domain_label, device=device)\n            reconstructed_imgs = decoder(z, domain_labels)\n\n            # Classification accuracy\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n            # Losses\n            clf_loss = clf_loss_fn(outputs, labels)\n            recon_loss = F.mse_loss(reconstructed_imgs, inputs, reduction=\"sum\")\n            total_clf_loss += clf_loss.item()\n            total_recon_loss += recon_loss.item()\n\n    accuracy = correct / total\n    avg_clf_loss = total_clf_loss / len(dataloader.dataset)\n    avg_recon_loss = total_recon_loss / len(dataloader.dataset)\n    return accuracy, avg_clf_loss, avg_recon_loss","metadata":{"execution":{"iopub.status.busy":"2024-10-04T13:01:46.542449Z","iopub.execute_input":"2024-10-04T13:01:46.542751Z","iopub.status.idle":"2024-10-04T13:01:46.557373Z","shell.execute_reply.started":"2024-10-04T13:01:46.542719Z","shell.execute_reply":"2024-10-04T13:01:46.556527Z"},"trusted":true},"execution_count":102,"outputs":[]},{"cell_type":"code","source":"def evaluate_on_all_domains(encoder, classifier, decoders, domains, data_path, device):\n    print(\"\\nFinal Evaluation on All Domains\\n\")\n    for domain in domains:\n        eval_dataloader = get_dataloader(data_path, domain)\n        domain_label = domains.index(domain)\n        accuracy, avg_clf_loss, avg_recon_loss = evaluate_model(\n            encoder,\n            classifier,\n            decoders[domain],\n            eval_dataloader,\n            device,\n            domain_label,\n        )\n        print(f\"Domain: {domain}\")\n        print(f\"  Accuracy: {accuracy * 100:.2f}%\")\n        print(f\"  Avg Classification Loss: {avg_clf_loss:.4f}\")\n        print(f\"  Avg Reconstruction Loss: {avg_recon_loss:.4f}\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-10-04T13:01:46.558482Z","iopub.execute_input":"2024-10-04T13:01:46.558812Z","iopub.status.idle":"2024-10-04T13:01:46.571393Z","shell.execute_reply.started":"2024-10-04T13:01:46.558779Z","shell.execute_reply":"2024-10-04T13:01:46.570529Z"},"trusted":true},"execution_count":103,"outputs":[]},{"cell_type":"code","source":"# Main training and evaluation script\nDATA_PATH = (\n    \"/kaggle/input/pacs-dataset/kfold\"  # Update this path to your dataset location\n)\nlatent_dim = 256\nnum_classes = 7  # Update this according to your PACS dataset\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# Domains in PACS dataset\ndomains = [\"art_painting\", \"cartoon\", \"photo\", \"sketch\"]\n\n# Initialize models\nencoder = Encoder(latent_dim).to(device)\ndecoders = {domain: Decoder(latent_dim, len(domains)).to(device) for domain in domains}\nclassifier = Classifier(latent_dim, num_classes).to(device)\n\n# Optimizer and Scheduler\nparams = list(encoder.parameters()) + list(classifier.parameters())\nfor decoder in decoders.values():\n    params += list(decoder.parameters())\noptimizer = optim.AdamW(params, lr=1e-4, weight_decay=1e-5)\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)\n\n# Create a combined DataLoader for all domains\ncombined_dataloader = get_combined_dataloader(DATA_PATH, domains)\n\n# Train model using progressive domain training\ntrain_model_progressive(\n  encoder,\n  decoders,\n  classifier,\n  domains,\n  combined_dataloader,\n  optimizer,\n  scheduler,\n  num_epochs=100,\n  device=device,\n  patience=10\n)\n\n# Final evaluation on all domains\nevaluate_on_all_domains(encoder, classifier, decoders, domains, DATA_PATH, device)","metadata":{"execution":{"iopub.status.busy":"2024-10-04T13:01:46.573159Z","iopub.execute_input":"2024-10-04T13:01:46.573463Z","iopub.status.idle":"2024-10-04T14:49:56.108476Z","shell.execute_reply.started":"2024-10-04T13:01:46.573432Z","shell.execute_reply":"2024-10-04T14:49:56.107540Z"},"trusted":true},"execution_count":104,"outputs":[{"name":"stdout","text":"Using device: cuda\nEpoch 1/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 313/313 [02:52<00:00,  1.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1, Loss: 44819868.0096\nEpoch 2/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 313/313 [02:09<00:00,  2.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2, Loss: 37957506.8179\nEpoch 3/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 313/313 [02:12<00:00,  2.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3, Loss: 35689299.5048\nEpoch 4/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 313/313 [02:14<00:00,  2.32it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4, Loss: 34525172.2556\nEpoch 5/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 313/313 [02:10<00:00,  2.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5, Loss: 33574778.1997\nEpoch 6/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 313/313 [02:08<00:00,  2.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6, Loss: 32987901.3642\nEpoch 7/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 313/313 [02:09<00:00,  2.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7, Loss: 31990916.3882\nEpoch 8/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 313/313 [02:09<00:00,  2.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8, Loss: 31945094.9481\nEpoch 9/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 313/313 [02:10<00:00,  2.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9, Loss: 31503885.2748\nEpoch 10/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 313/313 [02:10<00:00,  2.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10, Loss: 31011889.5559\nEpoch 11/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 313/313 [02:09<00:00,  2.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 11, Loss: 30379192.5911\nEpoch 12/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 313/313 [02:08<00:00,  2.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 12, Loss: 30133699.9185\nEpoch 13/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 313/313 [02:09<00:00,  2.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 13, Loss: 29827970.6326\nEpoch 14/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 313/313 [02:09<00:00,  2.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 14, Loss: 29001233.0703\nEpoch 15/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 313/313 [02:08<00:00,  2.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 15, Loss: 28628659.2500\nEpoch 16/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 313/313 [02:08<00:00,  2.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 16, Loss: 28149144.6597\nEpoch 17/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 313/313 [02:09<00:00,  2.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 17, Loss: 28263901.5575\nEpoch 18/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 313/313 [02:07<00:00,  2.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 18, Loss: 28417963.1246\nEpoch 19/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 313/313 [02:08<00:00,  2.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 19, Loss: 28203282.2604\nEpoch 20/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 313/313 [02:09<00:00,  2.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 20, Loss: 27136287.1917\nEpoch 21/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 313/313 [02:07<00:00,  2.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 21, Loss: 27500083.1118\nEpoch 22/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 313/313 [02:06<00:00,  2.48it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 22, Loss: 27069740.1118\nEpoch 23/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 313/313 [02:07<00:00,  2.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 23, Loss: 26895216.2684\nEpoch 24/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 313/313 [02:05<00:00,  2.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 24, Loss: 26856977.1526\nEpoch 25/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 313/313 [02:07<00:00,  2.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 25, Loss: 27038827.5623\nEpoch 26/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 313/313 [02:10<00:00,  2.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 26, Loss: 26348817.5367\nEpoch 27/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 313/313 [02:06<00:00,  2.47it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 27, Loss: 26180900.3411\nEpoch 28/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 313/313 [02:11<00:00,  2.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 28, Loss: 26306832.1510\nEpoch 29/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 313/313 [02:10<00:00,  2.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 29, Loss: 26217685.0527\nEpoch 30/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 313/313 [02:08<00:00,  2.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 30, Loss: 26117391.4345\nEpoch 31/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 313/313 [02:09<00:00,  2.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 31, Loss: 26160169.5631\nEpoch 32/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 313/313 [02:09<00:00,  2.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 32, Loss: 26028985.7029\nEpoch 33/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 313/313 [02:09<00:00,  2.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 33, Loss: 26249249.4010\nEpoch 34/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 313/313 [02:07<00:00,  2.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 34, Loss: 25911353.5911\nEpoch 35/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 313/313 [02:11<00:00,  2.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 35, Loss: 25704476.5958\nEpoch 36/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 313/313 [02:12<00:00,  2.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 36, Loss: 26234883.5823\nEpoch 37/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 313/313 [02:12<00:00,  2.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 37, Loss: 25705016.1422\nEpoch 38/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 313/313 [02:09<00:00,  2.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 38, Loss: 25820578.7812\nEpoch 39/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 313/313 [02:08<00:00,  2.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 39, Loss: 25141059.5224\nEpoch 40/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 313/313 [02:09<00:00,  2.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 40, Loss: 25394478.7348\nEpoch 41/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 313/313 [02:11<00:00,  2.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 41, Loss: 25835922.5990\nEpoch 42/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 313/313 [02:11<00:00,  2.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 42, Loss: 25795979.2636\nEpoch 43/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 313/313 [02:10<00:00,  2.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 43, Loss: 25757505.9856\nEpoch 44/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 313/313 [02:10<00:00,  2.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 44, Loss: 25369754.3946\nEpoch 45/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 313/313 [02:08<00:00,  2.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 45, Loss: 25523892.6310\nEpoch 46/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 313/313 [02:09<00:00,  2.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 46, Loss: 25437369.9665\nEpoch 47/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 313/313 [02:09<00:00,  2.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 47, Loss: 25240194.3706\nEpoch 48/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 313/313 [02:09<00:00,  2.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 48, Loss: 25605277.6046\nEpoch 49/100\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 313/313 [02:09<00:00,  2.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 49, Loss: 25951982.9441\nEarly stopping triggered after 49 epochs\n\nFinal Evaluation on All Domains\n\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|██████████| 64/64 [00:23<00:00,  2.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"Domain: art_painting\n  Accuracy: 41.60%\n  Avg Classification Loss: 0.0512\n  Avg Reconstruction Loss: 182955.4641\n\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|██████████| 74/74 [00:23<00:00,  3.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Domain: cartoon\n  Accuracy: 45.35%\n  Avg Classification Loss: 0.0502\n  Avg Reconstruction Loss: 245128.7253\n\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|██████████| 53/53 [00:18<00:00,  2.85it/s]\n","output_type":"stream"},{"name":"stdout","text":"Domain: photo\n  Accuracy: 66.41%\n  Avg Classification Loss: 0.0368\n  Avg Reconstruction Loss: 177599.3864\n\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|██████████| 123/123 [00:34<00:00,  3.56it/s]","output_type":"stream"},{"name":"stdout","text":"Domain: sketch\n  Accuracy: 39.96%\n  Avg Classification Loss: 0.0483\n  Avg Reconstruction Loss: 258051.7423\n\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]}]}
{"cells":[{"cell_type":"code","execution_count":78,"metadata":{"_cell_guid":"4f436e96-ef21-4124-b43a-f3a7eb31b6cf","_uuid":"161a57a5-c9a7-47a3-87cd-6d351a6cdb92","collapsed":false,"execution":{"iopub.execute_input":"2024-10-05T18:28:02.866749Z","iopub.status.busy":"2024-10-05T18:28:02.865667Z","iopub.status.idle":"2024-10-05T18:28:02.872700Z","shell.execute_reply":"2024-10-05T18:28:02.871668Z","shell.execute_reply.started":"2024-10-05T18:28:02.866705Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms, models\n","from tqdm import tqdm\n","from PIL import Image\n","import os\n","import torch.nn.functional as F\n","from torch.nn.modules.loss import _WeightedLoss\n","from sklearn.model_selection import train_test_split\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2"]},{"cell_type":"code","execution_count":79,"metadata":{"_cell_guid":"94b1820c-4753-470c-8f95-aab713e66535","_uuid":"013a8b5e-7432-4915-a2c0-9a8f5daaaff1","collapsed":false,"execution":{"iopub.execute_input":"2024-10-05T18:28:02.875511Z","iopub.status.busy":"2024-10-05T18:28:02.874928Z","iopub.status.idle":"2024-10-05T18:28:02.887803Z","shell.execute_reply":"2024-10-05T18:28:02.887003Z","shell.execute_reply.started":"2024-10-05T18:28:02.875464Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["import random\n","import numpy as np\n","\n","def set_random_seeds(seed_value=42):\n","    torch.manual_seed(seed_value)\n","    torch.cuda.manual_seed(seed_value)\n","    torch.cuda.manual_seed_all(seed_value)  # if you are using multi-GPU.\n","    np.random.seed(seed_value)  # Numpy module.\n","    random.seed(seed_value)  # Python random module.\n","    torch.backends.cudnn.benchmark = False\n","    torch.backends.cudnn.deterministic = True\n","\n","set_random_seeds()"]},{"cell_type":"code","execution_count":80,"metadata":{"execution":{"iopub.execute_input":"2024-10-05T18:28:02.889259Z","iopub.status.busy":"2024-10-05T18:28:02.888908Z","iopub.status.idle":"2024-10-05T18:28:02.902514Z","shell.execute_reply":"2024-10-05T18:28:02.901536Z","shell.execute_reply.started":"2024-10-05T18:28:02.889225Z"},"trusted":true},"outputs":[],"source":["class PACSDataset(Dataset):\n","    def __init__(self, root_dir, domains, transform=None):\n","        self.root_dir = root_dir\n","        self.domains = domains\n","        self.transform = transform\n","        self.images = []\n","        self.labels = []\n","        self._load_images_labels()\n","\n","    def _load_images_labels(self):\n","        for domain in self.domains:\n","            domain_dir = os.path.join(self.root_dir, domain)\n","            classes = sorted(\n","                [\n","                    d\n","                    for d in os.listdir(domain_dir)\n","                    if os.path.isdir(os.path.join(domain_dir, d))\n","                ]\n","            )\n","\n","            for label, class_name in enumerate(classes):\n","                class_dir = os.path.join(domain_dir, class_name)\n","                for image_name in os.listdir(class_dir):\n","                    if image_name.endswith((\".png\", \".jpg\", \".jpeg\")):\n","                        self.images.append(os.path.join(class_dir, image_name))\n","                        self.labels.append(label)\n","\n","    def __len__(self):\n","        return len(self.images)\n","\n","    def __getitem__(self, idx):\n","        image_path = self.images[idx]\n","        image = Image.open(image_path).convert(\"RGB\")\n","        label = self.labels[idx]\n","\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        return image, label\n","\n","\n","def get_transform():\n","    return transforms.Compose([\n","        transforms.Resize((224, 224)),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.RandomRotation(10),\n","        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","        transforms.RandomErasing(p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3), value=0),\n","    ])"]},{"cell_type":"code","execution_count":81,"metadata":{"_cell_guid":"633a724d-b68c-45bb-ab3c-e88e9115dbbc","_uuid":"9cc659f6-3f5a-4ddd-96c2-737a8c49e42a","collapsed":false,"execution":{"iopub.execute_input":"2024-10-05T18:28:02.903977Z","iopub.status.busy":"2024-10-05T18:28:02.903658Z","iopub.status.idle":"2024-10-05T18:28:02.916108Z","shell.execute_reply":"2024-10-05T18:28:02.915321Z","shell.execute_reply.started":"2024-10-05T18:28:02.903944Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["def get_dataloader(root_dir, train_domains, test_domain, batch_size=32):\n","    train_dataset = PACSDataset(root_dir, train_domains, transform=get_transform())\n","    val_dataset = PACSDataset(root_dir, train_domains, transform=get_transform())\n","    test_dataset = PACSDataset(root_dir, [test_domain], transform=get_transform())\n","    \n","    # Chia train và validation\n","    train_size = int(0.8 * len(train_dataset))\n","    val_size = len(train_dataset) - train_size\n","    train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n","    \n","    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n","    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n","    \n","    return train_loader, val_loader, test_loader"]},{"cell_type":"code","execution_count":82,"metadata":{"_cell_guid":"77b09e73-481d-48f2-be3d-49a15d8c6777","_uuid":"258e95c8-5d7d-4888-a00d-0a5e99aaa736","collapsed":false,"execution":{"iopub.execute_input":"2024-10-05T18:28:02.919480Z","iopub.status.busy":"2024-10-05T18:28:02.919008Z","iopub.status.idle":"2024-10-05T18:28:02.942117Z","shell.execute_reply":"2024-10-05T18:28:02.941193Z","shell.execute_reply.started":"2024-10-05T18:28:02.919409Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["from torchvision.models import efficientnet_b1\n","\n","class Encoder(nn.Module):\n","    def __init__(self, latent_dim):\n","        super(Encoder, self).__init__()\n","\n","        # Khởi tạo mô hình EfficientNet-B1 mà không sử dụng pretrained weights\n","        self.efficientnet = efficientnet_b1(weights=None)  # Khởi tạo từ đầu, không pretrained\n","\n","        # Lấy số features từ lớp cuối cùng của EfficientNet-B1\n","        in_features = self.efficientnet.classifier[1].in_features\n","\n","        # Attention mechanism\n","        self.attention = nn.Sequential(\n","            nn.Linear(in_features, in_features // 16),\n","            nn.ReLU(),\n","            nn.Linear(in_features // 16, in_features),\n","            nn.Sigmoid(),\n","        )\n","\n","        # Mean (mu) and log-variance (logvar) layers\n","        self.fc_mu = nn.Linear(in_features, latent_dim)\n","        self.fc_logvar = nn.Linear(in_features, latent_dim)\n","\n","        self.dropout = nn.Dropout(0.5)  # Add dropout\n","\n","    def forward(self, x):\n","        # Pass input through EfficientNet feature extractor\n","        features = self.efficientnet.features(x)\n","        x = self.efficientnet.avgpool(features)\n","        x = torch.flatten(x, 1)\n","\n","        x = self.dropout(x)  # Apply dropout\n","\n","        # Apply attention\n","        attention_weights = self.attention(x)\n","        x = x * attention_weights\n","\n","        # Compute mu and logvar\n","        mu = self.fc_mu(x)\n","        logvar = self.fc_logvar(x)\n","        return mu, logvar\n","\n","class ResidualBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(ResidualBlock, self).__init__()\n","        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n","        self.bn1 = nn.BatchNorm2d(out_channels)\n","        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n","        self.bn2 = nn.BatchNorm2d(out_channels)\n","\n","        self.shortcut = nn.Sequential()\n","        if in_channels != out_channels:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_channels, out_channels, kernel_size=1),\n","                nn.BatchNorm2d(out_channels),\n","            )\n","\n","    def forward(self, x):\n","        residual = x\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.bn2(self.conv2(out))\n","        out += self.shortcut(residual)\n","        out = F.relu(out)\n","        return out\n","\n","\n","class Decoder(nn.Module):\n","    def __init__(self, latent_dim, num_domains):\n","        super(Decoder, self).__init__()\n","\n","        self.domain_embedding = nn.Embedding(num_domains, latent_dim)\n","\n","        self.fc = nn.Linear(latent_dim, 512 * 7 * 7)\n","\n","        self.decoder = nn.Sequential(\n","            ResidualBlock(512, 256),\n","            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),\n","            nn.BatchNorm2d(128),\n","            nn.ReLU(),\n","            ResidualBlock(128, 128),\n","            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(),\n","            ResidualBlock(64, 64),\n","            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),\n","            nn.BatchNorm2d(32),\n","            nn.ReLU(),\n","            nn.ConvTranspose2d(32, 16, kernel_size=4, stride=2, padding=1),\n","            nn.BatchNorm2d(16),\n","            nn.ReLU(),\n","            nn.ConvTranspose2d(16, 3, kernel_size=4, stride=2, padding=1),\n","            nn.Tanh()  # Thêm Tanh để đảm bảo đầu ra trong khoảng [-1, 1]\n","        )\n","\n","        # Attention mechanism\n","        self.attention = nn.Sequential(nn.Conv2d(3, 1, kernel_size=1), nn.Sigmoid())\n","\n","    def forward(self, z, domain_label):\n","        domain_embed = self.domain_embedding(domain_label)\n","        z = z + domain_embed\n","\n","        x = self.fc(z)\n","        x = x.view(-1, 512, 7, 7)\n","        x = self.decoder(x)\n","\n","        # Apply attention\n","        attention_map = self.attention(x)\n","        x = x * attention_map\n","\n","        return x\n","\n","\n","class Classifier(nn.Module):\n","    def __init__(self, latent_dim, num_classes):\n","        super(Classifier, self).__init__()\n","        self.fc = nn.Linear(latent_dim, num_classes)\n","        self.dropout = nn.Dropout(0.5)\n","\n","    def forward(self, z):\n","        z = self.dropout(z)\n","        return self.fc(z)"]},{"cell_type":"code","execution_count":83,"metadata":{"_cell_guid":"a89bca72-9054-4ba9-8fe9-2b0c6572733e","_uuid":"fe7418a5-f00f-4fb1-8992-1bc42af2c5d3","collapsed":false,"execution":{"iopub.execute_input":"2024-10-05T18:28:03.073958Z","iopub.status.busy":"2024-10-05T18:28:03.073626Z","iopub.status.idle":"2024-10-05T18:28:03.089410Z","shell.execute_reply":"2024-10-05T18:28:03.088417Z","shell.execute_reply.started":"2024-10-05T18:28:03.073924Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["class LabelSmoothingLoss(_WeightedLoss):\n","    def __init__(self, weight=None, reduction=\"mean\", smoothing=0.0):\n","        super().__init__(weight=weight, reduction=reduction)\n","        self.smoothing = smoothing\n","        self.weight = weight\n","        self.reduction = reduction\n","\n","    def k_one_hot(self, targets: torch.Tensor, n_classes: int, smoothing=0.0):\n","        with torch.no_grad():\n","            targets = (\n","                torch.empty(size=(targets.size(0), n_classes), device=targets.device)\n","                .fill_(smoothing / (n_classes - 1))\n","                .scatter_(1, targets.data.unsqueeze(1), 1.0 - smoothing)\n","            )\n","        return targets\n","\n","    def reduce_loss(self, loss):\n","        return (\n","            loss.mean()\n","            if self.reduction == \"mean\"\n","            else loss.sum() if self.reduction == \"sum\" else loss\n","        )\n","\n","    def forward(self, inputs, targets):\n","        assert 0 <= self.smoothing < 1\n","\n","        targets = self.k_one_hot(targets, inputs.size(-1), self.smoothing)\n","        log_preds = F.log_softmax(inputs, -1)\n","\n","        if self.weight is not None:\n","            log_preds = log_preds * self.weight.unsqueeze(0)\n","\n","        return self.reduce_loss(-(targets * log_preds).sum(dim=-1))\n","\n","class DynamicWeightBalancer:\n","    def __init__(self, init_alpha=1.0, init_beta=1.0, init_gamma=1.0, patience=5, scaling_factor=0.8):\n","        self.alpha = init_alpha  # Reconstruction loss weight\n","        self.beta = init_beta    # Classification loss weight\n","        self.gamma = init_gamma  # KL divergence weight\n","        self.patience = patience\n","        self.scaling_factor = scaling_factor\n","        self.best_loss = float('inf')\n","        self.counter = 0\n","\n","    def update(self, current_loss, recon_loss, clf_loss, kl_loss):\n","        if current_loss < self.best_loss:\n","            self.best_loss = current_loss\n","            self.counter = 0\n","        else:\n","            self.counter += 1\n","\n","        if self.counter >= self.patience:\n","            self.counter = 0\n","            # Increase classification weight and decrease others\n","            self.beta /= self.scaling_factor\n","            self.alpha *= self.scaling_factor\n","            self.gamma *= self.scaling_factor\n","\n","        # Ensure classification loss weight is always significantly larger\n","        total_weight = self.alpha + self.beta + self.gamma\n","        self.alpha = max(0.1, min(0.3, self.alpha / total_weight))\n","        self.beta = max(0.6, min(0.8, self.beta / total_weight))\n","        self.gamma = 1 - self.alpha - self.beta\n","\n","        return self.alpha, self.beta, self.gamma"]},{"cell_type":"code","execution_count":84,"metadata":{"execution":{"iopub.execute_input":"2024-10-05T18:28:03.091553Z","iopub.status.busy":"2024-10-05T18:28:03.091248Z","iopub.status.idle":"2024-10-05T18:28:03.103185Z","shell.execute_reply":"2024-10-05T18:28:03.102371Z","shell.execute_reply.started":"2024-10-05T18:28:03.091521Z"},"trusted":true},"outputs":[],"source":["def reparameterize(mu, logvar, dropout_rate=0.5):\n","    std = torch.exp(0.5 * logvar)\n","    eps = torch.randn_like(std)\n","    z = mu + eps * std\n","    z = F.dropout(z, p=dropout_rate, training=True)  # Apply dropout\n","    return z\n","\n","def compute_loss(reconstructed_imgs_list, original_imgs, mu, logvar, predicted_labels, true_labels, clf_loss_fn, epoch, total_epochs, balancer):\n","    recon_loss = sum(\n","        F.mse_loss(recon, original_imgs, reduction=\"mean\")\n","        for recon in reconstructed_imgs_list\n","    ) / len(reconstructed_imgs_list)\n","\n","    kld_loss = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n","    clf_loss = clf_loss_fn(predicted_labels, true_labels)\n","\n","    alpha, beta, gamma = balancer.update(recon_loss + clf_loss + kld_loss, recon_loss, clf_loss, kld_loss)\n","\n","    total_loss = alpha * recon_loss + beta * clf_loss + gamma * kld_loss\n","    return total_loss, recon_loss.item(), clf_loss.item(), kld_loss.item(), alpha, beta, gamma"]},{"cell_type":"code","execution_count":85,"metadata":{"_cell_guid":"5963984d-caaf-4e6c-abff-b2ced9337abb","_uuid":"64e2706d-9120-4121-9358-b00c42985b97","collapsed":false,"execution":{"iopub.execute_input":"2024-10-05T18:28:03.105123Z","iopub.status.busy":"2024-10-05T18:28:03.104521Z","iopub.status.idle":"2024-10-05T18:28:03.116531Z","shell.execute_reply":"2024-10-05T18:28:03.115720Z","shell.execute_reply.started":"2024-10-05T18:28:03.105077Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["def mixup_data(x, y, alpha=1.0, device=\"cuda\"):\n","    if alpha > 0:\n","        lam = np.random.beta(alpha, alpha)\n","    else:\n","        lam = 1\n","\n","    batch_size = x.size()[0]\n","    index = torch.randperm(batch_size).to(device)\n","\n","    mixed_x = lam * x + (1 - lam) * x[index, :]\n","    y_a, y_b = y, y[index]\n","    return mixed_x, y_a, y_b, lam\n","\n","\n","def mixup_criterion(criterion, pred, y_a, y_b, lam):\n","    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)"]},{"cell_type":"code","execution_count":86,"metadata":{"execution":{"iopub.execute_input":"2024-10-05T18:28:03.118026Z","iopub.status.busy":"2024-10-05T18:28:03.117736Z","iopub.status.idle":"2024-10-05T18:28:03.144949Z","shell.execute_reply":"2024-10-05T18:28:03.144118Z","shell.execute_reply.started":"2024-10-05T18:28:03.117993Z"},"trusted":true},"outputs":[],"source":["import copy\n","\n","def train_model_progressive(\n","    encoder,\n","    decoders,\n","    classifier,\n","    train_domains,\n","    test_domain,\n","    train_loader,\n","    val_loader,\n","    test_loader,\n","    optimizer,\n","    scheduler,\n","    num_epochs=100,\n","    device=\"cuda\",\n","    patience=10,\n","):\n","    print(\"Training model with progressive domain adaptation\")\n","    print(f\"Number of epochs: {num_epochs}\")\n","    print(f\"Patience: {patience}\")\n","    print(f\"Train domains: {train_domains}\")\n","    print(f\"Test domain: {test_domain}\")\n","    print(f\"Device: {device}\")\n","    print(f\"Number of training samples: {len(train_loader.dataset)}\")\n","    print(f\"Number of validation samples: {len(val_loader.dataset)}\")\n","    print(f\"Number of test samples: {len(test_loader.dataset)}\")\n","\n","    clf_loss_fn = LabelSmoothingLoss(smoothing=0.1)\n","    domain_to_idx = {domain: idx for idx, domain in enumerate(train_domains + [test_domain])}\n","\n","    best_loss = float(\"inf\")\n","    best_test_accuracy = 0.0\n","    patience_counter = 0\n","    balancer = DynamicWeightBalancer()\n","\n","    # Để lưu mô hình tốt nhất\n","    best_model = {\n","        'encoder': None,\n","        'decoders': None,\n","        'classifier': None\n","    }\n","\n","    for epoch in range(num_epochs):\n","        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n","        encoder.train()\n","        classifier.train()\n","        for domain in train_domains:\n","            decoders[domain].train()\n","\n","        running_loss = 0.0\n","        running_recon_loss = 0.0\n","        running_clf_loss = 0.0\n","        running_kl_loss = 0.0\n","        total_samples = 0\n","\n","        # Training loop on train dataset\n","        for inputs, labels in tqdm(train_loader, desc=\"Training\"):\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","            inputs, labels_a, labels_b, lam = mixup_data(\n","                inputs, labels, alpha=0.2, device=device\n","            )\n","\n","            mu, logvar = encoder(inputs)\n","            z = reparameterize(mu, logvar)\n","\n","            reconstructed_imgs_list = []\n","            for domain in train_domains:\n","                domain_label = torch.tensor(\n","                    [domain_to_idx[domain]] * inputs.size(0), device=device\n","                )\n","                reconstructed_imgs = decoders[domain](z, domain_label)\n","                reconstructed_imgs_list.append(reconstructed_imgs)\n","\n","            predicted_labels = classifier(z)\n","\n","            loss, recon_loss, clf_loss, kl_loss, alpha, beta, gamma = compute_loss(\n","                reconstructed_imgs_list,\n","                inputs,\n","                mu,\n","                logvar,\n","                predicted_labels,\n","                labels,\n","                lambda pred, target: mixup_criterion(\n","                    clf_loss_fn, pred, labels_a, labels_b, lam\n","                ),\n","                epoch,\n","                num_epochs,\n","                balancer,\n","            )\n","\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","            running_loss += loss.item() * inputs.size(0)\n","            running_recon_loss += recon_loss * inputs.size(0)\n","            running_clf_loss += clf_loss * inputs.size(0)\n","            running_kl_loss += kl_loss * inputs.size(0)\n","            total_samples += inputs.size(0)\n","\n","        avg_loss = running_loss / total_samples\n","        avg_recon_loss = running_recon_loss / total_samples\n","        avg_clf_loss = running_clf_loss / total_samples\n","        avg_kl_loss = running_kl_loss / total_samples\n","\n","        print(\n","            f\"Epoch {epoch + 1}, Loss: {avg_loss:.4f}, Recon: {avg_recon_loss:.4f}, Clf: {avg_clf_loss:.4f}, KL: {avg_kl_loss:.4f}\"\n","        )\n","        print(f\"Weights - Alpha: {alpha:.4f}, Beta: {beta:.4f}, Gamma: {gamma:.4f}\")\n","\n","        # Validation\n","        encoder.eval()\n","        classifier.eval()\n","        for domain in train_domains:\n","            decoders[domain].eval()\n","\n","        val_running_loss = 0.0\n","        with torch.no_grad():\n","            for inputs, labels in tqdm(val_loader, desc=\"Validating\"):\n","                inputs, labels = inputs.to(device), labels.to(device)\n","\n","                mu, logvar = encoder(inputs)\n","                z = reparameterize(mu, logvar)\n","\n","                reconstructed_imgs_list = []\n","                for domain in train_domains:\n","                    domain_label = torch.tensor(\n","                        [domain_to_idx[domain]] * inputs.size(0), device=device\n","                    )\n","                    reconstructed_imgs = decoders[domain](z, domain_label)\n","                    reconstructed_imgs_list.append(reconstructed_imgs)\n","\n","                predicted_labels = classifier(z)\n","\n","                val_loss, _, _, _, _, _, _ = compute_loss(\n","                    reconstructed_imgs_list,\n","                    inputs,\n","                    mu,\n","                    logvar,\n","                    predicted_labels,\n","                    labels,\n","                    clf_loss_fn,\n","                    epoch,\n","                    num_epochs,\n","                    balancer,\n","                )\n","\n","                val_running_loss += val_loss.item()\n","\n","        avg_val_loss = val_running_loss / len(val_loader)\n","        print(f\"Validation Loss: {avg_val_loss:.4f}\")\n","\n","        # Đánh giá trên tập test\n","        if (epoch + 1) % 1 == 0:\n","            print(f\"--- Evaluating on Test Domain ({test_domain}) at Epoch {epoch + 1} ---\")\n","            test_accuracy, test_loss = evaluate_model(\n","                encoder,\n","                classifier,\n","                test_loader,\n","                device\n","            )\n","            print(f\"Test Accuracy: {test_accuracy:.2f}%, Test Loss: {test_loss:.4f}\")\n","\n","            # Save best model based on test accuracy\n","            if test_accuracy > best_test_accuracy:\n","                best_test_accuracy = test_accuracy\n","                best_model['encoder'] = copy.deepcopy(encoder.state_dict())\n","                best_model['decoders'] = {domain: copy.deepcopy(decoder.state_dict()) for domain, decoder in decoders.items()}\n","                best_model['classifier'] = copy.deepcopy(classifier.state_dict())\n","                print(f\"New best model saved with test accuracy: {best_test_accuracy:.2f}%\")\n","\n","\n","        # Early stopping based on validation loss\n","        if avg_val_loss < best_loss:\n","            best_loss = avg_val_loss\n","            patience_counter = 0\n","        else:\n","            patience_counter += 1\n","            if patience_counter >= patience:\n","                print(f\"Early stopping triggered after {epoch + 1} epochs\")\n","                break\n","\n","        scheduler.step(avg_val_loss)\n","\n","    # Load best model\n","    encoder.load_state_dict(best_model['encoder'])\n","    for domain, state_dict in best_model['decoders'].items():\n","        decoders[domain].load_state_dict(state_dict)\n","    classifier.load_state_dict(best_model['classifier'])\n","\n","    print(f\"Training completed. Best test accuracy: {best_test_accuracy:.2f}%\")\n","\n","    return encoder, decoders, classifier"]},{"cell_type":"code","execution_count":87,"metadata":{"_cell_guid":"2a3716ee-a41f-40f9-be92-6e13201957fc","_uuid":"c9b6247e-a3a8-4139-97cf-47beb2962809","collapsed":false,"execution":{"iopub.execute_input":"2024-10-05T18:28:03.147390Z","iopub.status.busy":"2024-10-05T18:28:03.147073Z","iopub.status.idle":"2024-10-05T18:28:03.159246Z","shell.execute_reply":"2024-10-05T18:28:03.158485Z","shell.execute_reply.started":"2024-10-05T18:28:03.147357Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["def evaluate_model(encoder, classifier, dataloader, device):\n","    encoder.eval()\n","    classifier.eval()\n","    correct = 0\n","    total = 0\n","    running_loss = 0.0\n","    clf_loss_fn = nn.CrossEntropyLoss()\n","\n","    with torch.no_grad():\n","        for inputs, labels in dataloader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            mu, logvar = encoder(inputs)\n","            z = reparameterize(mu, logvar)\n","            outputs = classifier(z)\n","            \n","            loss = clf_loss_fn(outputs, labels)\n","            running_loss += loss.item() * inputs.size(0)\n","            \n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","    accuracy = 100 * correct / total\n","    avg_loss = running_loss / total\n","    return accuracy, avg_loss"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"674a907d-466e-49d6-b8e9-fc6483ee92f3","_uuid":"9339af62-d3b0-4922-b5a6-52ddb95a57f5","collapsed":false,"execution":{"iopub.execute_input":"2024-10-05T18:28:03.160687Z","iopub.status.busy":"2024-10-05T18:28:03.160315Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Using device: cuda\n","Training model with progressive domain adaptation\n","Number of epochs: 100\n","Patience: 10\n","Train domains: ['art_painting', 'photo', 'sketch']\n","Test domain: cartoon\n","Device: cuda\n","Number of training samples: 6117\n","Number of validation samples: 1530\n","Number of test samples: 2344\n","Epoch 1/100\n"]},{"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 192/192 [01:35<00:00,  2.01it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1, Loss: 2.1385, Recon: 2.4655, Clf: 2.3503, KL: 0.0302\n","Weights - Alpha: 0.1000, Beta: 0.8000, Gamma: 0.1000\n"]},{"name":"stderr","output_type":"stream","text":["Validating: 100%|██████████| 48/48 [00:15<00:00,  3.10it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Validation Loss: 1.9077\n","--- Evaluating on Test Domain (cartoon) at Epoch 1 ---\n","Test Accuracy: 16.30%, Test Loss: 2.1794\n","New best model saved with test accuracy: 16.30%\n","Epoch 2/100\n"]},{"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 192/192 [01:35<00:00,  2.01it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 2, Loss: 1.9805, Recon: 2.1567, Clf: 2.1982, KL: 0.0626\n","Weights - Alpha: 0.1000, Beta: 0.8000, Gamma: 0.1000\n"]},{"name":"stderr","output_type":"stream","text":["Validating: 100%|██████████| 48/48 [00:15<00:00,  3.01it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Validation Loss: 1.8136\n","--- Evaluating on Test Domain (cartoon) at Epoch 2 ---\n","Test Accuracy: 14.59%, Test Loss: 2.1374\n","Epoch 3/100\n"]},{"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 192/192 [01:34<00:00,  2.02it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 3, Loss: 1.8720, Recon: 1.9849, Clf: 2.0785, KL: 0.1076\n","Weights - Alpha: 0.1000, Beta: 0.8000, Gamma: 0.1000\n"]},{"name":"stderr","output_type":"stream","text":["Validating: 100%|██████████| 48/48 [00:15<00:00,  3.01it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Validation Loss: 1.7028\n","--- Evaluating on Test Domain (cartoon) at Epoch 3 ---\n","Test Accuracy: 17.45%, Test Loss: 2.0171\n","New best model saved with test accuracy: 17.45%\n","Epoch 4/100\n"]},{"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 192/192 [01:35<00:00,  2.01it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 4, Loss: 1.7882, Recon: 1.8425, Clf: 1.9844, KL: 0.1644\n","Weights - Alpha: 0.1000, Beta: 0.8000, Gamma: 0.1000\n"]},{"name":"stderr","output_type":"stream","text":["Validating: 100%|██████████| 48/48 [00:16<00:00,  2.96it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Validation Loss: 1.6371\n","--- Evaluating on Test Domain (cartoon) at Epoch 4 ---\n","Test Accuracy: 20.56%, Test Loss: 1.9613\n","New best model saved with test accuracy: 20.56%\n","Epoch 5/100\n"]},{"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 192/192 [01:35<00:00,  2.00it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 5, Loss: 1.7227, Recon: 1.8250, Clf: 1.8976, KL: 0.2211\n","Weights - Alpha: 0.1000, Beta: 0.8000, Gamma: 0.1000\n"]},{"name":"stderr","output_type":"stream","text":["Validating: 100%|██████████| 48/48 [00:16<00:00,  2.98it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Validation Loss: 1.5768\n","--- Evaluating on Test Domain (cartoon) at Epoch 5 ---\n","Test Accuracy: 23.21%, Test Loss: 1.9174\n","New best model saved with test accuracy: 23.21%\n","Epoch 6/100\n"]},{"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 192/192 [01:35<00:00,  2.02it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 6, Loss: 1.6726, Recon: 1.7934, Clf: 1.8328, KL: 0.2703\n","Weights - Alpha: 0.1000, Beta: 0.8000, Gamma: 0.1000\n"]},{"name":"stderr","output_type":"stream","text":["Validating: 100%|██████████| 48/48 [00:15<00:00,  3.11it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Validation Loss: 1.5616\n","--- Evaluating on Test Domain (cartoon) at Epoch 6 ---\n","Test Accuracy: 24.91%, Test Loss: 1.9020\n","New best model saved with test accuracy: 24.91%\n","Epoch 7/100\n"]},{"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 192/192 [01:34<00:00,  2.03it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 7, Loss: 1.6482, Recon: 1.7697, Clf: 1.8008, KL: 0.3058\n","Weights - Alpha: 0.1000, Beta: 0.8000, Gamma: 0.1000\n"]},{"name":"stderr","output_type":"stream","text":["Validating: 100%|██████████| 48/48 [00:15<00:00,  3.02it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Validation Loss: 1.5498\n","--- Evaluating on Test Domain (cartoon) at Epoch 7 ---\n","Test Accuracy: 21.54%, Test Loss: 1.9352\n","Epoch 8/100\n"]},{"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 192/192 [01:35<00:00,  2.02it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 8, Loss: 1.6238, Recon: 1.7319, Clf: 1.7717, KL: 0.3328\n","Weights - Alpha: 0.1000, Beta: 0.8000, Gamma: 0.1000\n"]},{"name":"stderr","output_type":"stream","text":["Validating: 100%|██████████| 48/48 [00:15<00:00,  3.15it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Validation Loss: 1.5175\n","--- Evaluating on Test Domain (cartoon) at Epoch 8 ---\n","Test Accuracy: 24.79%, Test Loss: 1.8664\n","Epoch 9/100\n"]},{"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 192/192 [01:34<00:00,  2.03it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 9, Loss: 1.6098, Recon: 1.7090, Clf: 1.7552, KL: 0.3475\n","Weights - Alpha: 0.1000, Beta: 0.8000, Gamma: 0.1000\n"]},{"name":"stderr","output_type":"stream","text":["Validating: 100%|██████████| 48/48 [00:15<00:00,  3.17it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Validation Loss: 1.4723\n","--- Evaluating on Test Domain (cartoon) at Epoch 9 ---\n","Test Accuracy: 22.78%, Test Loss: 1.9639\n","Epoch 10/100\n"]},{"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 192/192 [01:35<00:00,  2.01it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 10, Loss: 1.5763, Recon: 1.7185, Clf: 1.7103, KL: 0.3617\n","Weights - Alpha: 0.1000, Beta: 0.8000, Gamma: 0.1000\n"]},{"name":"stderr","output_type":"stream","text":["Validating: 100%|██████████| 48/48 [00:15<00:00,  3.01it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Validation Loss: 1.4588\n","--- Evaluating on Test Domain (cartoon) at Epoch 10 ---\n","Test Accuracy: 26.62%, Test Loss: 1.8824\n","New best model saved with test accuracy: 26.62%\n","Epoch 11/100\n"]},{"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 192/192 [01:35<00:00,  2.01it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 11, Loss: 1.5535, Recon: 1.6557, Clf: 1.6882, KL: 0.3743\n","Weights - Alpha: 0.1000, Beta: 0.8000, Gamma: 0.1000\n"]},{"name":"stderr","output_type":"stream","text":["Validating: 100%|██████████| 48/48 [00:15<00:00,  3.02it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Validation Loss: 1.4351\n","--- Evaluating on Test Domain (cartoon) at Epoch 11 ---\n","Test Accuracy: 25.09%, Test Loss: 1.8670\n","Epoch 12/100\n"]},{"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 192/192 [01:34<00:00,  2.03it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 12, Loss: 1.5405, Recon: 1.6247, Clf: 1.6760, KL: 0.3728\n","Weights - Alpha: 0.1000, Beta: 0.8000, Gamma: 0.1000\n"]},{"name":"stderr","output_type":"stream","text":["Validating: 100%|██████████| 48/48 [00:16<00:00,  2.99it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Validation Loss: 1.4147\n","--- Evaluating on Test Domain (cartoon) at Epoch 12 ---\n","Test Accuracy: 29.22%, Test Loss: 1.8103\n","New best model saved with test accuracy: 29.22%\n","Epoch 13/100\n"]},{"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 192/192 [01:35<00:00,  2.02it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 13, Loss: 1.5037, Recon: 1.6409, Clf: 1.6271, KL: 0.3798\n","Weights - Alpha: 0.1000, Beta: 0.8000, Gamma: 0.1000\n"]},{"name":"stderr","output_type":"stream","text":["Validating: 100%|██████████| 48/48 [00:15<00:00,  3.02it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Validation Loss: 1.4133\n","--- Evaluating on Test Domain (cartoon) at Epoch 13 ---\n","Test Accuracy: 26.37%, Test Loss: 1.8695\n","Epoch 14/100\n"]},{"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 192/192 [01:35<00:00,  2.02it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 14, Loss: 1.4912, Recon: 1.6133, Clf: 1.6153, KL: 0.3755\n","Weights - Alpha: 0.1000, Beta: 0.8000, Gamma: 0.1000\n"]},{"name":"stderr","output_type":"stream","text":["Validating: 100%|██████████| 48/48 [00:15<00:00,  3.18it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Validation Loss: 1.3752\n","--- Evaluating on Test Domain (cartoon) at Epoch 14 ---\n","Test Accuracy: 29.14%, Test Loss: 1.8502\n","Epoch 15/100\n"]},{"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 192/192 [01:34<00:00,  2.04it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 15, Loss: 1.4620, Recon: 1.6102, Clf: 1.5794, KL: 0.3740\n","Weights - Alpha: 0.1000, Beta: 0.8000, Gamma: 0.1000\n"]},{"name":"stderr","output_type":"stream","text":["Validating: 100%|██████████| 48/48 [00:15<00:00,  3.09it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Validation Loss: 1.3427\n","--- Evaluating on Test Domain (cartoon) at Epoch 15 ---\n","Test Accuracy: 32.21%, Test Loss: 1.7636\n","New best model saved with test accuracy: 32.21%\n","Epoch 16/100\n"]},{"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 192/192 [01:35<00:00,  2.02it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 16, Loss: 1.4551, Recon: 1.5825, Clf: 1.5742, KL: 0.3752\n","Weights - Alpha: 0.1000, Beta: 0.8000, Gamma: 0.1000\n"]},{"name":"stderr","output_type":"stream","text":["Validating: 100%|██████████| 48/48 [00:16<00:00,  2.92it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Validation Loss: 1.3224\n","--- Evaluating on Test Domain (cartoon) at Epoch 16 ---\n","Test Accuracy: 27.94%, Test Loss: 1.8567\n","Epoch 17/100\n"]},{"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 192/192 [01:35<00:00,  2.00it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 17, Loss: 1.4343, Recon: 1.5824, Clf: 1.5486, KL: 0.3722\n","Weights - Alpha: 0.1000, Beta: 0.8000, Gamma: 0.1000\n"]},{"name":"stderr","output_type":"stream","text":["Validating: 100%|██████████| 48/48 [00:16<00:00,  2.92it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Validation Loss: 1.2822\n","--- Evaluating on Test Domain (cartoon) at Epoch 17 ---\n","Test Accuracy: 32.68%, Test Loss: 1.7719\n","New best model saved with test accuracy: 32.68%\n","Epoch 18/100\n"]},{"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 192/192 [01:35<00:00,  2.01it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 18, Loss: 1.4142, Recon: 1.5825, Clf: 1.5229, KL: 0.3757\n","Weights - Alpha: 0.1000, Beta: 0.8000, Gamma: 0.1000\n"]},{"name":"stderr","output_type":"stream","text":["Validating: 100%|██████████| 48/48 [00:16<00:00,  2.95it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Validation Loss: 1.2821\n","--- Evaluating on Test Domain (cartoon) at Epoch 18 ---\n","Test Accuracy: 34.17%, Test Loss: 1.7515\n","New best model saved with test accuracy: 34.17%\n","Epoch 19/100\n"]},{"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 192/192 [01:36<00:00,  1.99it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19, Loss: 1.3983, Recon: 1.5589, Clf: 1.5071, KL: 0.3675\n","Weights - Alpha: 0.1000, Beta: 0.8000, Gamma: 0.1000\n"]},{"name":"stderr","output_type":"stream","text":["Validating: 100%|██████████| 48/48 [00:15<00:00,  3.04it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Validation Loss: 1.2539\n","--- Evaluating on Test Domain (cartoon) at Epoch 19 ---\n","Test Accuracy: 35.92%, Test Loss: 1.6923\n","New best model saved with test accuracy: 35.92%\n","Epoch 20/100\n"]},{"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 192/192 [01:35<00:00,  2.01it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20, Loss: 1.3760, Recon: 1.5884, Clf: 1.4747, KL: 0.3741\n","Weights - Alpha: 0.1000, Beta: 0.8000, Gamma: 0.1000\n"]},{"name":"stderr","output_type":"stream","text":["Validating: 100%|██████████| 48/48 [00:16<00:00,  2.99it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Validation Loss: 1.2475\n","--- Evaluating on Test Domain (cartoon) at Epoch 20 ---\n","Test Accuracy: 36.65%, Test Loss: 1.6891\n","New best model saved with test accuracy: 36.65%\n","Epoch 21/100\n"]},{"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 192/192 [01:36<00:00,  2.00it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 21, Loss: 1.3585, Recon: 1.5602, Clf: 1.4563, KL: 0.3744\n","Weights - Alpha: 0.1000, Beta: 0.8000, Gamma: 0.1000\n"]},{"name":"stderr","output_type":"stream","text":["Validating: 100%|██████████| 48/48 [00:16<00:00,  2.99it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Validation Loss: 1.2113\n","--- Evaluating on Test Domain (cartoon) at Epoch 21 ---\n","Test Accuracy: 38.65%, Test Loss: 1.6574\n","New best model saved with test accuracy: 38.65%\n","Epoch 22/100\n"]},{"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 192/192 [01:35<00:00,  2.00it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 22, Loss: 1.3543, Recon: 1.5061, Clf: 1.4594, KL: 0.3619\n","Weights - Alpha: 0.1000, Beta: 0.8000, Gamma: 0.1000\n"]},{"name":"stderr","output_type":"stream","text":["Validating: 100%|██████████| 48/48 [00:16<00:00,  2.96it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Validation Loss: 1.2057\n","--- Evaluating on Test Domain (cartoon) at Epoch 22 ---\n","Test Accuracy: 37.07%, Test Loss: 1.6705\n","Epoch 23/100\n"]},{"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 192/192 [01:36<00:00,  1.99it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 23, Loss: 1.3477, Recon: 1.4946, Clf: 1.4530, KL: 0.3588\n","Weights - Alpha: 0.1000, Beta: 0.8000, Gamma: 0.1000\n"]},{"name":"stderr","output_type":"stream","text":["Validating: 100%|██████████| 48/48 [00:15<00:00,  3.02it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Validation Loss: 1.1992\n","--- Evaluating on Test Domain (cartoon) at Epoch 23 ---\n","Test Accuracy: 39.29%, Test Loss: 1.6292\n","New best model saved with test accuracy: 39.29%\n","Epoch 24/100\n"]},{"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 192/192 [01:34<00:00,  2.02it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 24, Loss: 1.3360, Recon: 1.4990, Clf: 1.4376, KL: 0.3608\n","Weights - Alpha: 0.1000, Beta: 0.8000, Gamma: 0.1000\n"]},{"name":"stderr","output_type":"stream","text":["Validating: 100%|██████████| 48/48 [00:15<00:00,  3.06it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Validation Loss: 1.1703\n","--- Evaluating on Test Domain (cartoon) at Epoch 24 ---\n","Test Accuracy: 40.15%, Test Loss: 1.6282\n","New best model saved with test accuracy: 40.15%\n","Epoch 25/100\n"]},{"name":"stderr","output_type":"stream","text":["Training: 100%|██████████| 192/192 [01:34<00:00,  2.03it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 25, Loss: 1.3224, Recon: 1.4813, Clf: 1.4227, KL: 0.3611\n","Weights - Alpha: 0.1000, Beta: 0.8000, Gamma: 0.1000\n"]},{"name":"stderr","output_type":"stream","text":["Validating: 100%|██████████| 48/48 [00:15<00:00,  3.10it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Validation Loss: 1.1567\n","--- Evaluating on Test Domain (cartoon) at Epoch 25 ---\n","Test Accuracy: 40.23%, Test Loss: 1.5875\n","New best model saved with test accuracy: 40.23%\n","Epoch 26/100\n"]},{"name":"stderr","output_type":"stream","text":["Training:  72%|███████▏  | 139/192 [01:08<00:26,  2.03it/s]"]}],"source":["# Main training and evaluation script\n","DATA_PATH = \"/kaggle/input/pacs-dataset/kfold\"\n","latent_dim = 256\n","num_classes = 7\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")\n","\n","train_domains = [\"art_painting\", \"photo\", \"sketch\"]\n","test_domain = \"cartoon\"\n","all_domains = train_domains + [test_domain]\n","\n","# Initialize models\n","encoder = Encoder(latent_dim).to(device)\n","decoders = {domain: Decoder(latent_dim, len(all_domains)).to(device) for domain in all_domains}\n","classifier = Classifier(latent_dim, num_classes).to(device)\n","\n","# Optimizer and Scheduler\n","params = list(encoder.parameters()) + list(classifier.parameters())\n","for decoder in decoders.values():\n","    params += list(decoder.parameters())\n","\n","optimizer = optim.AdamW(params, lr=1e-4, weight_decay=1e-5)\n","scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.1, patience=5)\n","\n","# Get dataloaders\n","train_loader, val_loader, test_loader = get_dataloader(DATA_PATH, train_domains, test_domain)\n","\n","# Train model\n","encoder, decoders, classifier = train_model_progressive(\n","    encoder,\n","    decoders,\n","    classifier,\n","    train_domains,\n","    test_domain,\n","    train_loader,\n","    val_loader,\n","    test_loader,\n","    optimizer,\n","    scheduler,\n","    num_epochs=100,\n","    device=device,\n","    patience=10,\n",")\n","\n","# Final evaluation on all domains\n","print(\"Final evaluation on all domains\")\n","for domain in all_domains:\n","    _, _, test_loader = get_dataloader(DATA_PATH, train_domains, domain)\n","    test_accuracy, test_loss = evaluate_model(\n","        encoder, classifier, test_loader, device\n","    )\n","    print(f\"Test Accuracy ({domain}): {test_accuracy:.2f}%, Test Loss: {test_loss:.4f}\")\n","\n","# Final evaluation on the test domain\n","print(f\"Final evaluation on test domain: {test_domain}\")\n","test_accuracy, test_loss = evaluate_model(\n","    encoder, classifier, test_loader, device\n",")\n","print(f\"Test Accuracy: {test_accuracy:.2f}%, Test Loss: {test_loss:.4f}\")"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":5815134,"sourceId":9545143,"sourceType":"datasetVersion"}],"dockerImageVersionId":30786,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
